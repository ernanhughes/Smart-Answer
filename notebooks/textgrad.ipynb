{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No engine provided. Either provide an engine as the argument to this call, or use `textgrad.set_backward_engine(engine)` to set the backward engine.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Define textual feedback as a loss function\u001b[39;00m\n\u001b[0;32m     13\u001b[0m evaluation_instruction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluate if the response follows a correct step-by-step approach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 14\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluation_instruction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Compute the loss and optimize\u001b[39;00m\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(answer)\n",
      "File \u001b[1;32md:\\projects\\Smart-Answer\\venv\\Lib\\site-packages\\textgrad\\loss.py:36\u001b[0m, in \u001b[0;36mTextLoss.__init__\u001b[1;34m(self, eval_system_prompt, engine)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_system_prompt \u001b[38;5;241m=\u001b[39m eval_system_prompt\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (SingletonBackwardEngine()\u001b[38;5;241m.\u001b[39mget_engine() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo engine provided. Either provide an engine as the argument to this call, or use `textgrad.set_backward_engine(engine)` to set the backward engine.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     engine \u001b[38;5;241m=\u001b[39m SingletonBackwardEngine()\u001b[38;5;241m.\u001b[39mget_engine()\n",
      "\u001b[1;31mException\u001b[0m: No engine provided. Either provide an engine as the argument to this call, or use `textgrad.set_backward_engine(engine)` to set the backward engine."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import textgrad as tg\n",
    "\n",
    "# Define a math problem\n",
    "question = tg.Variable(\"What is the sum of the first 100 positive integers?\", \n",
    "                       role_description=\"question for llm\",\n",
    "                       requires_grad=False)\n",
    "\n",
    "# Get the initial response\n",
    "model = tg.BlackboxLLM(\"gpt-4o\")\n",
    "answer = model(question)\n",
    "\n",
    "# Define textual feedback as a loss function\n",
    "evaluation_instruction = \"Evaluate if the response follows a correct step-by-step approach.\"\n",
    "loss_fn = tg.TextLoss(evaluation_instruction)\n",
    "\n",
    "# Compute the loss and optimize\n",
    "loss = loss_fn(answer)\n",
    "loss.backward()\n",
    "optimizer = tg.TGD(parameters=[answer])\n",
    "optimizer.step()\n",
    "\n",
    "# Print the refined response\n",
    "print(\"Optimized Answer:\", answer.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import textgrad as tg\n",
    "PROMPT_TO_OPTIMIZE = \"You are a concise LLM. Think step by step.\"\n",
    "question = tg.Variable(f\"{question}\", role_description=\"question to the LLM\", requires_grad=False) tg.Variable(f\"{answer}\", role_description=\"answer to the question\", requires_grad=False) \n",
    "ground_truth = tg.Variable(f\"{answer}\", role_description=\"question to the LLM\", requires_grad=False) tg.Variable(f\"{answer}\", role_description=\"answer to the question\", requires_grad=False) \n",
    "system_prompt = tg.Variable(PROMPT_TO_OPTIMIZE, role_description=\"system prompt\", requires_grad=True)\n",
    "\n",
    "model = tg.BlackboxLLM(llm_engine, system_prompt=system_prompt)\n",
    "optimizer = tg.TGD(parameters=list(model.parameters())) # Textual Gradient Descent\n",
    "\n",
    "prediction = model(question)\n",
    "results = {\"prediction\" : prediction, \"ground_truth_answer\" : ground_truth}\n",
    "loss = eval_fn(results) # pytorch-like loss\n",
    "loss.backward() # pytorch-like backward\n",
    "optimizer.step() # pytorch-like optimization step\n",
    "print(system_prompt) # a new and improved system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how long it will take to dry 30 shirts under the sun, we need to consider the drying process and whether it depends on the number of shirts or not.\n",
      "\n",
      "1. **Understanding the Drying Process**: Drying shirts under the sun is typically a process that depends on the exposure to sunlight and air circulation. If the shirts are spread out properly, each shirt will dry independently of the others. This means that the drying time for one shirt is the same as for multiple shirts, provided they all have equal exposure to sunlight and air.\n",
      "\n",
      "2. **Given Information**: We know that it takes 1 hour to dry 25 shirts. This implies that each shirt is drying independently, and the drying time is not affected by the number of shirts, as long as they are all exposed to the same conditions.\n",
      "\n",
      "3. **Applying the Same Conditions to 30 Shirts**: If 25 shirts take 1 hour to dry, and the drying process is independent for each shirt, then 30 shirts will also take 1 hour to dry, assuming they are all laid out in a manner that allows them to receive the same amount of sunlight and air circulation as the 25 shirts.\n",
      "\n",
      "4. **Conclusion**: Therefore, it will take 1 hour to dry 30 shirts under the sun, given that the conditions (sunlight and air exposure) remain consistent for all shirts.\n",
      "\n",
      "This reasoning assumes that the drying capacity (space and exposure) is not a limiting factor. If space is limited and the shirts are overlapping or not all exposed equally, the drying time could be longer. However, based on the information provided, we assume optimal conditions.\n"
     ]
    }
   ],
   "source": [
    "import textgrad as tg\n",
    "tg.set_backward_engine(\"gpt-4o\", override=True)\n",
    "model = tg.BlackboxLLM(\"gpt-4o\")\n",
    "question_string = (\"If it takes 1 hour to dry 25 shirts under the sun, \"\n",
    "                   \"how long will it take to dry 30 shirts under the sun? \"\n",
    "                   \"Reason step by step\")\n",
    "question = tg.Variable(question_string, \n",
    "                       role_description=\"question to the LLM\", \n",
    "                       requires_grad=False)\n",
    "answer = model(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm here and ready to assist you. How can I help you today?\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textgrad import get_engine\n",
    "engine = get_engine(\"gpt-3.5-turbo\")\n",
    "engine.generate(\"Hello how are you?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<textgrad.loss.TextLoss at 0x20ba85485d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textgrad import Variable, TextLoss, get_engine\n",
    "engine = get_engine(\"gpt-3.5-turbo\")\n",
    "system_prompt = Variable(\"Evaluate the correctness of this sentence\", role_description=\"The system prompt\")\n",
    "loss = TextLoss(system_prompt, engine=engine)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Answer: The sum of the first \\( n \\) positive integers can be calculated using the formula:\n",
      "\n",
      "\\[\n",
      "S = \\frac{n(n + 1)}{2}\n",
      "\\]\n",
      "\n",
      "This formula originates from the observation that pairing numbers from opposite ends of the sequence (e.g., 1 and 100, 2 and 99, etc.) results in a constant sum. For \\( n \\) numbers, there are \\( \\frac{n}{2} \\) such pairs, each summing to \\( n + 1 \\).\n",
      "\n",
      "For the first 100 positive integers, \\( n = 100 \\). Plugging this into the formula gives:\n",
      "\n",
      "\\[\n",
      "S = \\frac{100 \\times 101}{2}\n",
      "\\]\n",
      "\n",
      "Breaking it down further:\n",
      "\n",
      "1. Multiply 100 by 101:\n",
      "\n",
      "   \\[\n",
      "   100 \\times 101 = 10100\n",
      "   \\]\n",
      "\n",
      "2. Divide the result by 2:\n",
      "\n",
      "   \\[\n",
      "   \\frac{10100}{2} = 5050\n",
      "   \\]\n",
      "\n",
      "Therefore, the sum of the first 100 positive integers is 5050.\n",
      "\n",
      "To visualize, imagine a number line with numbers 1 to 100. Pairing numbers from each end results in 50 pairs, each summing to 101.\n",
      "\n",
      "Alternative methods, such as using a loop to iterate through numbers 1 to 100 and summing them, can also achieve the same result. However, the formula is more efficient.\n",
      "\n",
      "Common mistakes include forgetting to divide by 2 or miscalculating the multiplication step. Always double-check calculations to avoid these errors.\n",
      "\n",
      "In real-world applications, this formula can be used in scenarios like calculating the total number of items in a sequentially numbered set, such as seats in a theater row.\n",
      "\n",
      "By understanding the origin and application of this formula, you can confidently calculate the sum of consecutive integers.\n"
     ]
    }
   ],
   "source": [
    "import textgrad as tg\n",
    "\n",
    "# Define a math problem\n",
    "question = tg.Variable(\"What is the sum of the first 100 positive integers?\", \n",
    "                       role_description=\"question to the LLM\", \n",
    "                       requires_grad=False)\n",
    "# Get the initial response\n",
    "model = tg.BlackboxLLM(\"gpt-4o\")\n",
    "answer = model(question)\n",
    "\n",
    "# Define textual feedback as a loss function\n",
    "evaluation_instruction = \"Evaluate if the response follows a correct step-by-step approach.\"\n",
    "loss_fn = tg.TextLoss(evaluation_instruction)\n",
    "\n",
    "# Compute the loss and optimize\n",
    "loss = loss_fn(answer)\n",
    "loss.backward()\n",
    "optimizer = tg.TGD(parameters=[answer])\n",
    "optimizer.step()\n",
    "# Print the refined response\n",
    "print(\"Optimized Answer:\", answer.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Answer: The sum of the first \\( n \\) positive integers can be calculated using the formula:\n",
      "\n",
      "\\[\n",
      "S = \\frac{n(n + 1)}{2}\n",
      "\\]\n",
      "\n",
      "This formula originates from the observation that pairing numbers from opposite ends of the sequence (e.g., 1 and 100, 2 and 99, etc.) results in a constant sum. For \\( n \\) numbers, there are \\( \\frac{n}{2} \\) such pairs, each summing to \\( n + 1 \\).\n",
      "\n",
      "For the first 100 positive integers, \\( n = 100 \\). Plugging this into the formula gives:\n",
      "\n",
      "\\[\n",
      "S = \\frac{100 \\times 101}{2}\n",
      "\\]\n",
      "\n",
      "Breaking it down further:\n",
      "\n",
      "1. Multiply 100 by 101:\n",
      "\n",
      "   \\[\n",
      "   100 \\times 101 = 10100\n",
      "   \\]\n",
      "\n",
      "2. Divide the result by 2:\n",
      "\n",
      "   \\[\n",
      "   \\frac{10100}{2} = 5050\n",
      "   \\]\n",
      "\n",
      "Therefore, the sum of the first 100 positive integers is 5050.\n",
      "\n",
      "To visualize, imagine a number line with numbers 1 to 100. Pairing numbers from each end results in 50 pairs, each summing to 101.\n",
      "\n",
      "Alternative methods, such as using a loop to iterate through numbers 1 to 100 and summing them, can also achieve the same result. However, the formula is more efficient.\n",
      "\n",
      "Common mistakes include forgetting to divide by 2 or miscalculating the multiplication step. Always double-check calculations to avoid these errors.\n",
      "\n",
      "In real-world applications, this formula can be used in scenarios like calculating the total number of items in a sequentially numbered set, such as seats in a theater row.\n",
      "\n",
      "By understanding the origin and application of this formula, you can confidently calculate the sum of consecutive integers.\n"
     ]
    }
   ],
   "source": [
    "answer.set_role_description(\"concise and accurate answer to the question\")\n",
    "\n",
    "# Step 2: Define the loss function and the optimizer, just like in PyTorch!\n",
    "# Here, we don't have SGD, but we have TGD (Textual Gradient Descent)\n",
    "# that works with \"textual gradients\".\n",
    "optimizer = tg.TGD(parameters=[answer])\n",
    "evaluation_instruction = (f\"Here's a question: {question_string}. \"\n",
    "                           \"Evaluate any given answer to this question, \"\n",
    "                           \"be smart, logical, and very critical. \"\n",
    "                           \"Just provide concise feedback.\")\n",
    "\n",
    "\n",
    "# TextLoss is a natural-language specified loss function that describes\n",
    "# how we want to evaluate the reasoning.\n",
    "loss_fn = tg.TextLoss(evaluation_instruction)\n",
    "print(\"Optimized Answer:\", answer.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable(value=This joke is a classic example of a play on words and physical comedy. It uses the setup of a common scenario—someone walking into a bar—and subverts expectations by adding a humorous twist. The punchline relies on the double meaning of \"walks into,\" suggesting both entering a place and physically bumping into objects. Whether it's considered good or not can depend on personal taste, as humor is subjective. Some might find it funny due to its simplicity and surprise element, while others might not find it as amusing., role=response from the language model, grads=set())"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textgrad import get_engine, Variable\n",
    "from textgrad.loss import TextLoss\n",
    "engine = get_engine(\"gpt-4o\")\n",
    "evaluation_instruction = Variable(\"Is ths a good joke?\", \n",
    "                                  role_description=\"question to the LLM\",\n",
    "                                  requires_grad=False)\n",
    "response_evaluator = TextLoss(evaluation_instruction, engine)\n",
    "response = Variable(\"A blind man walks into a bar. And a table. And a chair.\",\n",
    "                    role_description=\"question to the LLM\",\n",
    "                      requires_grad=True)\n",
    "response_evaluator(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is something about this sentence that is not quite right.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textgrad import get_engine, Variable, TextLoss, TextualGradientDescent\n",
    "x = Variable(\"Tre is somtin about this sentance tha tis not quite right.\", role_description=\"The input sentence\", requires_grad=True)\n",
    "x.gradients\n",
    "engine = get_engine(\"gpt-3.5-turbo\")\n",
    "system_prompt = Variable(\"Evaluate the correctness of this sentence\", role_description=\"The system prompt\")\n",
    "loss = TextLoss(system_prompt, engine=engine)\n",
    "optimizer = TextualGradientDescent(parameters=[x], engine=engine)\n",
    "l = loss(x)\n",
    "l.backward(engine)\n",
    "optimizer.step()\n",
    "x.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
