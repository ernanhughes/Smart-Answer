{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "import textgrad as tg\n",
    "from textgrad.autograd import MultimodalLLMCall\n",
    "from textgrad.loss import ImageQALoss\n",
    "\n",
    "\n",
    "import textgrad as tg\n",
    "from textgrad import get_engine, set_backward_engine\n",
    "\n",
    "MODEL_NAME = \"ollama/Qwen2.5\"\n",
    "\n",
    "engine = get_engine(f\"experimental:{MODEL_NAME}\", cache=False)\n",
    "# this also works with\n",
    "set_backward_engine(f\"experimental:{MODEL_NAME}\", cache=False, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import litellm\n",
    "from textgrad.engine_experimental.litellm import LiteLLMEngine\n",
    "\n",
    "litellm._turn_on_debug()\n",
    "\n",
    "\n",
    "LiteLLMEngine(MODEL_NAME, cache=True).generate(content=\"hello, what's 3+4\", system_prompt=\"you are an assistant\")\n",
    "\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/a/a7/Camponotus_flavomarginatus_ant.jpg\"\n",
    "image_data = httpx.get(image_url).content\n",
    "\n",
    "LiteLLMEngine(MODEL_NAME, cache=True).generate(content=[image_data, \"what is this my boy\"], system_prompt=\"you are an assistant\")\n",
    "tg.set_backward_engine(\"gpt-4o\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bee.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbee.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Read the local image file in binary mode\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      4\u001b[0m     image_data \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Print the first few bytes of the image data to verify (optional)\u001b[39;00m\n",
      "File \u001b[1;32md:\\projects\\Smart-Answer\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bee.jpg'"
     ]
    }
   ],
   "source": [
    "image_path = \"bee.jpg\"\n",
    "# Read the local image file in binary mode\n",
    "with open(image_path, 'rb') as file:\n",
    "    image_data = file.read()\n",
    "\n",
    "# Print the first few bytes of the image data to verify (optional)\n",
    "print(image_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_variable = tg.Variable(image_data, role_description=\"image to answer a question about\", requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable(value=This image shows a close-up of a honeybee collecting pollen. The bee is perched on a cluster of flowers, and you can see pollen attached to its hind legs. The details of the bee's body, including its wings, eyes, and fuzzy thorax, are clearly visible., role=response from the language model, grads=set())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_variable = tg.Variable(\"What do you see in this image?\", role_description=\"question\", requires_grad=False)\n",
    "response = MultimodalLLMCall(\"gpt-4o\")([image_variable, question_variable])\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable(value=The answer is mostly complete and accurate. It correctly identifies the main elements of the image: a honeybee collecting pollen, the presence of flowers, and the details of the bee's body. However, it could be improved by mentioning the specific type of flowers or plant if identifiable, and by describing the setting or background to provide more context. Additionally, it could note the color and texture details of the bee and flowers for a more vivid description., role=evaluation of the response from the language model, grads=set())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = ImageQALoss(\n",
    "    evaluation_instruction=\"Does this seem like a complete and good answer for the image? Criticize. Do not provide a new answer.\",\n",
    "    engine=\"gpt-4o\"\n",
    ")\n",
    "loss = loss_fn(question=question_variable, image=image_variable, response=response)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image shows a close-up of a honeybee collecting pollen. The bee is perched on a cluster of flowers, possibly from a plant like goldenrod, with pollen visibly attached to its hind legs. The details of the bee's body, including its translucent wings, large compound eyes, and fuzzy thorax, are clearly visible. The bee's distinctive black and yellow stripes add to its vibrant appearance. The background appears to be a natural setting, with earthy tones that complement the scene. This moment captures the bee's vital role in pollination, as it diligently gathers pollen, contributing to the ecosystem. The gentle hum of its wings adds a sense of life and movement to the image.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tg.TGD(parameters=[response])\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(response.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
