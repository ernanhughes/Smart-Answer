{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def get_model_response(prompt, model=\"gpt-4\", max_tokens=50):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        logprobs = True,\n",
    "        messages=[\n",
    "            {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    print(completion)\n",
    "    response_message = completion.choices[0].message.content\n",
    "    print(response_message)\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confidence(answer):\n",
    "    logprobs = answer[\"logprobs\"][\"token_logprobs\"]\n",
    "    confidence = sum(logprobs)  # Sum of log-probabilities\n",
    "    print(f\"Answer {answer} Confidence: {sum(logprobs)}\")\n",
    "    return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_qa(prompt, threshold=0.5):\n",
    "    response = get_model_response(prompt)\n",
    "    confidence = compute_confidence(response)\n",
    "    \n",
    "    if confidence < threshold:\n",
    "        return \"[No Answer]\"\n",
    "    return response[\"text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_utility(response, ground_truth, risk_penalty=-1):\n",
    "    if response == \"[No Answer]\":\n",
    "        return 0  # No reward or penalty\n",
    "    elif response == ground_truth:\n",
    "        return 1  # Correct answer reward\n",
    "    else:\n",
    "        return risk_penalty  # Incorrect answer penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_utility_vs_threshold(thresholds, responses, ground_truths, risk_penalty=-1):\n",
    "    utilities = [np.mean([evaluate_utility(resp, gt, risk_penalty) for resp, gt in zip(responses, ground_truths)])\n",
    "                 for t in thresholds]\n",
    "    \n",
    "    plt.plot(thresholds, utilities, marker='o', linestyle='-')\n",
    "    plt.xlabel(\"Confidence Threshold\")\n",
    "    plt.ylabel(\"Average Utility\")\n",
    "    plt.title(\"Impact of Confidence Threshold on Utility\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dataset = [\n",
    "    {\"question\": \"What is 12 + 25?\", \"answer\": \"37\"},\n",
    "    {\"question\": \"What is the capital of France?\", \"answer\": \"Paris\"},\n",
    "    {\"question\": \"Solve for x: 2x + 3 = 9\", \"answer\": \"x = 3\"},\n",
    "    {\"question\": \"What is the square root of 144?\", \"answer\": \"12\"},\n",
    "    {\"question\": \"Who wrote '1984'?\", \"answer\": \"George Orwell\"},\n",
    "    {\"question\": \"What is the derivative of x^2?\", \"answer\": \"2x\"},\n",
    "    {\"question\": \"What is full of holes but still holds water?\", \"answer\": \"sponge\"},\n",
    "    {\"question\": \"What can you break, even if you never pick it up or touch it?\", \"answer\": \"a promise\"},\n",
    "    {\"question\": \"What is always in front of you but canâ€™t be seen?\", \"answer\": \"the future\"},\n",
    "    {\"question\": \"What can run but never walks, has a mouth but never talks, has a head but never weeps, has a bed but never sleeps?\", \"answer\": \"river\"},\n",
    "    {\"question\": \"The more you take, the more you leave behind. What are they?\", \"answer\": \"footprints\"},\n",
    "    {\"question\": \"With pointed fangs, I sit and wait; with piercing force I crunch out fate; grabbing victims, proclaiming might; physically joining with a single bite. What am I?\", \"answer\": \"stapler\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(dataset, compute_budgets):\n",
    "    results = []\n",
    "    for compute_budget in compute_budgets:\n",
    "        print(f\"Testing with compute budget: {compute_budget} tokens...\")\n",
    "        for item in dataset:\n",
    "            response = get_model_response(item[\"question\"], max_tokens=compute_budget)\n",
    "            results.append({\n",
    "                \"question\": item[\"question\"],\n",
    "                \"ground_truth\": item[\"answer\"],\n",
    "                \"response\": response.strip(),\n",
    "                \"compute_budget\": compute_budget\n",
    "            })\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with compute budget: 10 tokens...\n",
      "ChatCompletion(id='chatcmpl-B482zpWUanXmxCJxZLKNMPNBvlM5I', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='12', bytes=[49, 50], logprob=-0.02815967, top_logprobs=[]), ChatCompletionTokenLogprob(token=' +', bytes=[32, 43], logprob=-9.610702e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-3.190179e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='25', bytes=[50, 53], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' equals', bytes=[32, 101, 113, 117, 97, 108, 115], logprob=-0.015039189, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.010042212, top_logprobs=[]), ChatCompletionTokenLogprob(token='37', bytes=[51, 55], logprob=-7.89631e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0012392756, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='12 + 25 equals 37.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323945, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=25, total_tokens=34, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "12 + 25 equals 37.\n",
      "ChatCompletion(id='chatcmpl-B482zU1cLBWmiTBJS6iICjhYWYuN8', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-2.220075e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' capital', bytes=[32, 99, 97, 112, 105, 116, 97, 108], logprob=-7.89631e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-2.4584822e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' France', bytes=[32, 70, 114, 97, 110, 99, 101], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Paris', bytes=[32, 80, 97, 114, 105, 115], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.00027277938, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The capital of France is Paris.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323945, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=8, prompt_tokens=24, total_tokens=32, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The capital of France is Paris.\n",
      "ChatCompletion(id='chatcmpl-B4830i3OM9v3kCsbpVqL8UHy0K1wI', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='To', bytes=[84, 111], logprob=-0.2881363, top_logprobs=[]), ChatCompletionTokenLogprob(token=' solve', bytes=[32, 115, 111, 108, 118, 101], logprob=-0.03039295, top_logprobs=[]), ChatCompletionTokenLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-0.1121289, top_logprobs=[]), ChatCompletionTokenLogprob(token=' x', bytes=[32, 120], logprob=-0.048443943, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.21431576, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.26061916, top_logprobs=[]), ChatCompletionTokenLogprob(token=' would', bytes=[32, 119, 111, 117, 108, 100], logprob=-2.1187372, top_logprobs=[]), ChatCompletionTokenLogprob(token=' first', bytes=[32, 102, 105, 114, 115, 116], logprob=-0.63639146, top_logprobs=[]), ChatCompletionTokenLogprob(token=' subtract', bytes=[32, 115, 117, 98, 116, 114, 97, 99, 116], logprob=-0.053501353, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.004749915, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-1.504853e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-0.0014987913, top_logprobs=[]), ChatCompletionTokenLogprob(token=' both', bytes=[32, 98, 111, 116, 104], logprob=-0.0357204, top_logprobs=[]), ChatCompletionTokenLogprob(token=' sides', bytes=[32, 115, 105, 100, 101, 115], logprob=-0.00018256421, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.17015636, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.0037460483, top_logprobs=[]), ChatCompletionTokenLogprob(token=' equation', bytes=[32, 101, 113, 117, 97, 116, 105, 111, 110], logprob=-0.0012274927, top_logprobs=[]), ChatCompletionTokenLogprob(token=':\\n\\n', bytes=[58, 10, 10], logprob=-0.7782672, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-0.0019048431, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-1.2664457e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' +', bytes=[32, 43], logprob=-0.019859385, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00033558503, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-7.89631e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' -', bytes=[32, 45], logprob=-0.003048416, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0019537294, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.0006682367, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-2.6060809e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='9', bytes=[57], logprob=-1.4140442e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' -', bytes=[32, 45], logprob=-6.46828e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0025596146, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='\\n', bytes=[10], logprob=-1.1530764, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-0.2965906, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-2.1008714e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.0012298732, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00019185843, top_logprobs=[]), ChatCompletionTokenLogprob(token='6', bytes=[54], logprob=-3.3213026e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='\\n\\n', bytes=[10, 10], logprob=-0.03226308, top_logprobs=[]), ChatCompletionTokenLogprob(token='Then', bytes=[84, 104, 101, 110], logprob=-0.054527886, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.45161125, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.75850886, top_logprobs=[]), ChatCompletionTokenLogprob(token=' divide', bytes=[32, 100, 105, 118, 105, 100, 101], logprob=-1.500922, top_logprobs=[]), ChatCompletionTokenLogprob(token=' each', bytes=[32, 101, 97, 99, 104], logprob=-2.145511, top_logprobs=[]), ChatCompletionTokenLogprob(token=' side', bytes=[32, 115, 105, 100, 101], logprob=-0.0004942946, top_logprobs=[]), ChatCompletionTokenLogprob(token=' by', bytes=[32, 98, 121], logprob=-0.117722236, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0009387355, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-3.5313153e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=':\\n\\n', bytes=[58, 10, 10], logprob=-0.26572433, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-0.08808035, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-2.9352968e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='/', bytes=[47], logprob=-0.9169257, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-0.00015347853, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.00070754817, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-6.4325184e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='6', bytes=[54], logprob=-2.577686e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='/', bytes=[47], logprob=-0.00015229016, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-2.6968896e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='\\n', bytes=[10], logprob=-0.05879993, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-0.0119042285, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.00096982205, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00039754162, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-9.372295e-06, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='To solve for x, you would first subtract 3 from both sides of the equation:\\n\\n2x + 3 - 3 = 9 - 3\\n2x = 6\\n\\nThen, you divide each side by 2:\\n\\n2x/2 = 6/2\\nx = 3', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323946, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=64, prompt_tokens=31, total_tokens=95, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "To solve for x, you would first subtract 3 from both sides of the equation:\n",
      "\n",
      "2x + 3 - 3 = 9 - 3\n",
      "2x = 6\n",
      "\n",
      "Then, you divide each side by 2:\n",
      "\n",
      "2x/2 = 6/2\n",
      "x = 3\n",
      "ChatCompletion(id='chatcmpl-B4832AMSsewv7v1B00Pw8Xl4lBsc0', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-4.3202e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' square', bytes=[32, 115, 113, 117, 97, 114, 101], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' root', bytes=[32, 114, 111, 111, 116], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-1.7432603e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-2.4584822e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='144', bytes=[49, 52, 52], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-5.5122365e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='12', bytes=[49, 50], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.00016694854, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The square root of 144 is 12.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323948, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=26, total_tokens=37, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The square root of 144 is 12.\n",
      "ChatCompletion(id='chatcmpl-B4835Ho6UrUnjiaiygFRS3GdEAs5k', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token=\"'\", bytes=[39], logprob=-0.054886002, top_logprobs=[]), ChatCompletionTokenLogprob(token='198', bytes=[49, 57, 56], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='4', bytes=[52], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"'\", bytes=[39], logprob=-1.8624639e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' was', bytes=[32, 119, 97, 115], logprob=-4.604148e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' written', bytes=[32, 119, 114, 105, 116, 116, 101, 110], logprob=-3.888926e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' by', bytes=[32, 98, 121], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' George', bytes=[32, 71, 101, 111, 114, 103, 101], logprob=-2.0100624e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Orwell', bytes=[32, 79, 114, 119, 101, 108, 108], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.00017338553, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content=\"'1984' was written by George Orwell.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323951, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=23, total_tokens=34, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "'1984' was written by George Orwell.\n",
      "ChatCompletion(id='chatcmpl-B4836mFZjvJXmdTcJ30dI7zbjvPTt', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-2.577686e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' derivative', bytes=[32, 100, 101, 114, 105, 118, 97, 116, 105, 118, 101], logprob=-1.7432603e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-4.3202e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' x', bytes=[32, 120], logprob=-9.372295e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='^', bytes=[94], logprob=-0.0031825865, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-3.4121115e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.027417988, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-3.22594e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0030377246, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The derivative of x^2 is 2x.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323952, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=26, total_tokens=38, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The derivative of x^2 is 2x.\n",
      "ChatCompletion(id='chatcmpl-B4837Pk0VirEOyIFrv2WqmQoV5YWu', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='A', bytes=[65], logprob=-0.007246907, top_logprobs=[]), ChatCompletionTokenLogprob(token=' sponge', bytes=[32, 115, 112, 111, 110, 103, 101], logprob=-1.147242e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.0032292907, top_logprobs=[]), ChatCompletionTokenLogprob(token=' full', bytes=[32, 102, 117, 108, 108], logprob=-2.9040899e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-3.650519e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' holes', bytes=[32, 104, 111, 108, 101, 115], logprob=-1.2664457e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-0.03294995, top_logprobs=[]), ChatCompletionTokenLogprob(token=' still', bytes=[32, 115, 116, 105, 108, 108], logprob=-0.014512626, top_logprobs=[]), ChatCompletionTokenLogprob(token=' holds', bytes=[32, 104, 111, 108, 100, 115], logprob=-3.1305768e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' water', bytes=[32, 119, 97, 116, 101, 114], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0030144302, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='A sponge is full of holes but still holds water.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323953, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=27, total_tokens=39, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "A sponge is full of holes but still holds water.\n",
      "ChatCompletion(id='chatcmpl-B4838eWjEjTjeG8zbbcWp3CH9eizX', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='You', bytes=[89, 111, 117], logprob=-0.05960898, top_logprobs=[]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-7.5411124e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' break', bytes=[32, 98, 114, 101, 97, 107], logprob=-1.3663626e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.012042284, top_logprobs=[]), ChatCompletionTokenLogprob(token=' promise', bytes=[32, 112, 114, 111, 109, 105, 115, 101], logprob=-2.58224e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' without', bytes=[32, 119, 105, 116, 104, 111, 117, 116], logprob=-0.61516744, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ever', bytes=[32, 101, 118, 101, 114], logprob=-1.0615803, top_logprobs=[]), ChatCompletionTokenLogprob(token=' picking', bytes=[32, 112, 105, 99, 107, 105, 110, 103], logprob=-0.03969417, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.0006212961, top_logprobs=[]), ChatCompletionTokenLogprob(token=' up', bytes=[32, 117, 112], logprob=-2.4584822e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' or', bytes=[32, 111, 114], logprob=-4.4849444e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' touching', bytes=[32, 116, 111, 117, 99, 104, 105, 110, 103], logprob=-0.0002699185, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-6.749814e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.006683872, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='You can break a promise without ever picking it up or touching it.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323954, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=15, prompt_tokens=33, total_tokens=48, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "You can break a promise without ever picking it up or touching it.\n",
      "ChatCompletion(id='chatcmpl-B4839j7lRgwipEmugNuP2Hqo4kp2n', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.0007275634, top_logprobs=[]), ChatCompletionTokenLogprob(token=' future', bytes=[32, 102, 117, 116, 117, 114, 101], logprob=-0.13740264, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.0016266216, top_logprobs=[]), ChatCompletionTokenLogprob(token=' always', bytes=[32, 97, 108, 119, 97, 121, 115], logprob=-6.5994034e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' in', bytes=[32, 105, 110], logprob=-6.869018e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' front', bytes=[32, 102, 114, 111, 110, 116], logprob=-3.1737043e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-2.7133641e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-1.3186812e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-0.044114888, top_logprobs=[]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-0.00882528, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"'t\", bytes=[39, 116], logprob=-0.1471958, top_logprobs=[]), ChatCompletionTokenLogprob(token=' be', bytes=[32, 98, 101], logprob=-1.0445127e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' seen', bytes=[32, 115, 101, 101, 110], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.012042284, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content=\"The future is always in front of you but can't be seen.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323955, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=15, prompt_tokens=30, total_tokens=45, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The future is always in front of you but can't be seen.\n",
      "ChatCompletion(id='chatcmpl-B483AUEjQdvDP6cs9ws8aczhLWb2h', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.006546501, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-0.00049322186, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0017283721, top_logprobs=[]), ChatCompletionTokenLogprob(token=' this', bytes=[32, 116, 104, 105, 115], logprob=-0.68620306, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-0.016555209, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-1.3663626e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-1.4378848e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.0683199, top_logprobs=[]), ChatCompletionTokenLogprob(token=' river', bytes=[32, 114, 105, 118, 101, 114], logprob=-0.08867016, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0010209017, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The answer to this riddle is a river.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323956, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=46, total_tokens=57, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to this riddle is a river.\n",
      "ChatCompletion(id='chatcmpl-B483A9xvbhQMBU0FxhsZRn4TrcVQY', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.113309495, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-0.0015620005, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.1134356, top_logprobs=[]), ChatCompletionTokenLogprob(token=' this', bytes=[32, 116, 104, 105, 115], logprob=-0.47234917, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-0.0013164278, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-8.418666e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.00025323365, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \"', bytes=[32, 34], logprob=-0.017321136, top_logprobs=[]), ChatCompletionTokenLogprob(token='foot', bytes=[102, 111, 111, 116], logprob=-0.041959744, top_logprobs=[]), ChatCompletionTokenLogprob(token='steps', bytes=[115, 116, 101, 112, 115], logprob=-0.011046534, top_logprobs=[]), ChatCompletionTokenLogprob(token='\".', bytes=[34, 46], logprob=-0.33444542, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The answer to this riddle is \"footsteps\".', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323956, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=32, total_tokens=44, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to this riddle is \"footsteps\".\n",
      "ChatCompletion(id='chatcmpl-B483BO6gCWDtO3PwLCR5yHGBk6sxs', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.12003197, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-0.008298008, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0014987913, top_logprobs=[]), ChatCompletionTokenLogprob(token=' your', bytes=[32, 121, 111, 117, 114], logprob=-1.151053, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-5.6769813e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-8.180258e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.0002730178, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \"', bytes=[32, 34], logprob=-0.5684459, top_logprobs=[]), ChatCompletionTokenLogprob(token='A', bytes=[65], logprob=-0.06718762, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Stap', bytes=[32, 83, 116, 97, 112], logprob=-0.0033656927, top_logprobs=[]), ChatCompletionTokenLogprob(token='ler', bytes=[108, 101, 114], logprob=-2.057744e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='\".', bytes=[34, 46], logprob=-0.075178504, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The answer to your riddle is \"A Stapler\".', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323957, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=13, prompt_tokens=53, total_tokens=66, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to your riddle is \"A Stapler\".\n",
      "Testing with compute budget: 30 tokens...\n",
      "ChatCompletion(id='chatcmpl-B483COEhfAvB1DZYd5BAjmxCLq07e', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='12', bytes=[49, 50], logprob=-0.044487227, top_logprobs=[]), ChatCompletionTokenLogprob(token=' +', bytes=[32, 43], logprob=-1.0087517e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-3.1424974e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='25', bytes=[50, 53], logprob=-1.2664457e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' equals', bytes=[32, 101, 113, 117, 97, 108, 115], logprob=-0.016821217, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.010754442, top_logprobs=[]), ChatCompletionTokenLogprob(token='37', bytes=[51, 55], logprob=-6.704273e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0028709695, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='12 + 25 equals 37.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323958, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=25, total_tokens=34, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "12 + 25 equals 37.\n",
      "ChatCompletion(id='chatcmpl-B483DIOGfajw4mBnBmHCmR9ArR1Ps', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-1.7432603e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' capital', bytes=[32, 99, 97, 112, 105, 116, 97, 108], logprob=-7.89631e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-1.9816675e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' France', bytes=[32, 70, 114, 97, 110, 99, 101], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Paris', bytes=[32, 80, 97, 114, 105, 115], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.00053146784, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The capital of France is Paris.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323959, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=8, prompt_tokens=24, total_tokens=32, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The capital of France is Paris.\n",
      "ChatCompletion(id='chatcmpl-B483DdtCiKynmm383mrgguZz8BDzV', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='To', bytes=[84, 111], logprob=-0.24458797, top_logprobs=[]), ChatCompletionTokenLogprob(token=' solve', bytes=[32, 115, 111, 108, 118, 101], logprob=-0.026000096, top_logprobs=[]), ChatCompletionTokenLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-0.13167885, top_logprobs=[]), ChatCompletionTokenLogprob(token=' x', bytes=[32, 120], logprob=-0.040199634, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.23609214, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.25732547, top_logprobs=[]), ChatCompletionTokenLogprob(token=' first', bytes=[32, 102, 105, 114, 115, 116], logprob=-2.1517637, top_logprobs=[]), ChatCompletionTokenLogprob(token=' subtract', bytes=[32, 115, 117, 98, 116, 114, 97, 99, 116], logprob=-0.57183707, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0027372318, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-9.0883464e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-0.0017500306, top_logprobs=[]), ChatCompletionTokenLogprob(token=' both', bytes=[32, 98, 111, 116, 104], logprob=-0.031470742, top_logprobs=[]), ChatCompletionTokenLogprob(token=' sides', bytes=[32, 115, 105, 100, 101, 115], logprob=-0.00021951001, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.14029846, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.0042074444, top_logprobs=[]), ChatCompletionTokenLogprob(token=' equation', bytes=[32, 101, 113, 117, 97, 116, 105, 111, 110], logprob=-0.0010027975, top_logprobs=[]), ChatCompletionTokenLogprob(token=':\\n\\n', bytes=[58, 10, 10], logprob=-0.6013689, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-0.0013757106, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-9.0883464e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' +', bytes=[32, 43], logprob=-0.024463162, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00026872646, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-5.5122365e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' -', bytes=[32, 45], logprob=-0.0018360644, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0020368914, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.00071243185, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-1.9146995e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='9', bytes=[57], logprob=-3.0545007e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' -', bytes=[32, 45], logprob=-4.978234e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.002671019, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-6.704273e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='\\n\\n', bytes=[10, 10], logprob=-1.003734, top_logprobs=[]), ChatCompletionTokenLogprob(token='This', bytes=[84, 104, 105, 115], logprob=-0.62907165, top_logprobs=[]), ChatCompletionTokenLogprob(token=' simpl', bytes=[32, 115, 105, 109, 112, 108], logprob=-0.07802737, top_logprobs=[]), ChatCompletionTokenLogprob(token='ifies', bytes=[105, 102, 105, 101, 115], logprob=-0.0008036722, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.019213388, top_logprobs=[]), ChatCompletionTokenLogprob(token=':\\n\\n', bytes=[58, 10, 10], logprob=-0.04512347, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-2.5226382e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-2.3392786e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.00036597464, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-9.901345e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='6', bytes=[54], logprob=-2.8160932e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='\\n\\n', bytes=[10, 10], logprob=-0.019627731, top_logprobs=[]), ChatCompletionTokenLogprob(token='Then', bytes=[84, 104, 101, 110], logprob=-0.15627338, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.5102081, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.4232015, top_logprobs=[]), ChatCompletionTokenLogprob(token=' would', bytes=[32, 119, 111, 117, 108, 100], logprob=-5.5220146, top_logprobs=[]), ChatCompletionTokenLogprob(token=' divide', bytes=[32, 100, 105, 118, 105, 100, 101], logprob=-0.0021094554, top_logprobs=[]), ChatCompletionTokenLogprob(token=' both', bytes=[32, 98, 111, 116, 104], logprob=-0.2042014, top_logprobs=[]), ChatCompletionTokenLogprob(token=' sides', bytes=[32, 115, 105, 100, 101, 115], logprob=-0.0005520791, top_logprobs=[]), ChatCompletionTokenLogprob(token=' by', bytes=[32, 98, 121], logprob=-0.5346033, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0009737557, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-1.147242e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=':\\n\\n', bytes=[58, 10, 10], logprob=-0.4006574, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-0.04522886, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-2.6968896e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' /', bytes=[32, 47], logprob=-0.34850013, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0018985291, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-1.147242e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.00046832662, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-1.27099975e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='6', bytes=[54], logprob=-2.1008714e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' /', bytes=[32, 47], logprob=-0.00023298002, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.001239514, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-1.6882126e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='\\n\\n', bytes=[10, 10], logprob=-0.018747145, top_logprobs=[]), ChatCompletionTokenLogprob(token='This', bytes=[84, 104, 105, 115], logprob=-1.205408, top_logprobs=[]), ChatCompletionTokenLogprob(token=' gives', bytes=[32, 103, 105, 118, 101, 115], logprob=-0.73793614, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.33381432, top_logprobs=[]), ChatCompletionTokenLogprob(token=':\\n\\n', bytes=[58, 10, 10], logprob=-0.3523589, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-0.00016671013, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.00010092071, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00019245445, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-1.9862217e-05, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='To solve for x, you first subtract 3 from both sides of the equation:\\n\\n2x + 3 - 3 = 9 - 3\\n\\nThis simplifies to:\\n\\n2x = 6\\n\\nThen, you would divide both sides by 2:\\n\\n2x / 2 = 6 / 2\\n\\nThis gives you:\\n\\nx = 3', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323959, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=75, prompt_tokens=31, total_tokens=106, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "To solve for x, you first subtract 3 from both sides of the equation:\n",
      "\n",
      "2x + 3 - 3 = 9 - 3\n",
      "\n",
      "This simplifies to:\n",
      "\n",
      "2x = 6\n",
      "\n",
      "Then, you would divide both sides by 2:\n",
      "\n",
      "2x / 2 = 6 / 2\n",
      "\n",
      "This gives you:\n",
      "\n",
      "x = 3\n",
      "ChatCompletion(id='chatcmpl-B483Hn55xs1d0bbtEeJF5OBqA1xmx', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-4.3202e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' square', bytes=[32, 115, 113, 117, 97, 114, 101], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' root', bytes=[32, 114, 111, 111, 116], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-2.220075e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-2.4584822e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='144', bytes=[49, 52, 52], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-5.5122365e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='12', bytes=[49, 50], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.00016957101, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The square root of 144 is 12.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323963, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=26, total_tokens=37, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The square root of 144 is 12.\n",
      "ChatCompletion(id='chatcmpl-B483Hnzgz5mIRktQlMRiKJ6xEoiFQ', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token=\"'\", bytes=[39], logprob=-0.02767243, top_logprobs=[]), ChatCompletionTokenLogprob(token='198', bytes=[49, 57, 56], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='4', bytes=[52], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"'\", bytes=[39], logprob=-1.7432603e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' was', bytes=[32, 119, 97, 115], logprob=-3.7697225e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' written', bytes=[32, 119, 114, 105, 116, 116, 101, 110], logprob=-3.650519e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' by', bytes=[32, 98, 121], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' George', bytes=[32, 71, 101, 111, 114, 103, 101], logprob=-1.5928495e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Orwell', bytes=[32, 79, 114, 119, 101, 108, 108], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.00015431295, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content=\"'1984' was written by George Orwell.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323963, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=23, total_tokens=34, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "'1984' was written by George Orwell.\n",
      "ChatCompletion(id='chatcmpl-B483IkpGECMBi92Pj7n1MN1JAqSAA', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-2.4584822e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' derivative', bytes=[32, 100, 101, 114, 105, 118, 97, 116, 105, 118, 101], logprob=-1.504853e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-5.5122365e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' x', bytes=[32, 120], logprob=-7.107425e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='^', bytes=[94], logprob=-0.0052077863, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-2.3392786e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.04791955, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-2.1411865e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0043959366, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The derivative of x^2 is 2x.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323964, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=26, total_tokens=38, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The derivative of x^2 is 2x.\n",
      "ChatCompletion(id='chatcmpl-B483JUyzAwnflR3z8ayXHt0hM89QA', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='A', bytes=[65], logprob=-0.0091343485, top_logprobs=[]), ChatCompletionTokenLogprob(token=' sponge', bytes=[32, 115, 112, 111, 110, 103, 101], logprob=-1.504853e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.0032239375, top_logprobs=[]), ChatCompletionTokenLogprob(token=' full', bytes=[32, 102, 117, 108, 108], logprob=-2.8802491e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-2.9352968e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' holes', bytes=[32, 104, 111, 108, 101, 115], logprob=-1.0280384e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-0.022337511, top_logprobs=[]), ChatCompletionTokenLogprob(token=' still', bytes=[32, 115, 116, 105, 108, 108], logprob=-0.01335222, top_logprobs=[]), ChatCompletionTokenLogprob(token=' holds', bytes=[32, 104, 111, 108, 100, 115], logprob=-3.059055e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' water', bytes=[32, 119, 97, 116, 101, 114], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0025184655, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='A sponge is full of holes but still holds water.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323965, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=27, total_tokens=39, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "A sponge is full of holes but still holds water.\n",
      "ChatCompletion(id='chatcmpl-B483KelTB1s2LYjdGYuRIdCNMhoHu', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-2.4587893, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-0.042570315, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.08304392, top_logprobs=[]), ChatCompletionTokenLogprob(token=' your', bytes=[32, 121, 111, 117, 114], logprob=-2.4183416, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-0.0023799269, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-5.2001665e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.0021672712, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \"', bytes=[32, 34], logprob=-0.41274273, top_logprobs=[]), ChatCompletionTokenLogprob(token='a', bytes=[97], logprob=-0.01829954, top_logprobs=[]), ChatCompletionTokenLogprob(token=' promise', bytes=[32, 112, 114, 111, 109, 105, 115, 101], logprob=-0.0007013569, top_logprobs=[]), ChatCompletionTokenLogprob(token='\".', bytes=[34, 46], logprob=-0.46951133, top_logprobs=[]), ChatCompletionTokenLogprob(token=' You', bytes=[32, 89, 111, 117], logprob=-0.09699978, top_logprobs=[]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-0.03147132, top_logprobs=[]), ChatCompletionTokenLogprob(token=' break', bytes=[32, 98, 114, 101, 97, 107], logprob=-0.035544503, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-3.851082, top_logprobs=[]), ChatCompletionTokenLogprob(token=' without', bytes=[32, 119, 105, 116, 104, 111, 117, 116], logprob=-0.10485276, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ever', bytes=[32, 101, 118, 101, 114], logprob=-1.0997676, top_logprobs=[]), ChatCompletionTokenLogprob(token=' physically', bytes=[32, 112, 104, 121, 115, 105, 99, 97, 108, 108, 121], logprob=-0.281016, top_logprobs=[]), ChatCompletionTokenLogprob(token=' touching', bytes=[32, 116, 111, 117, 99, 104, 105, 110, 103], logprob=-0.05669764, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.16058378, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.045847077, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The answer to your riddle is \"a promise\". You can break it without ever physically touching it.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323966, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=22, prompt_tokens=33, total_tokens=55, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to your riddle is \"a promise\". You can break it without ever physically touching it.\n",
      "ChatCompletion(id='chatcmpl-B483LSCfuGC8X6ZGWuTJTmIcbsqEV', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.0010062543, top_logprobs=[]), ChatCompletionTokenLogprob(token=' future', bytes=[32, 102, 117, 116, 117, 114, 101], logprob=-0.06044239, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.0014021444, top_logprobs=[]), ChatCompletionTokenLogprob(token=' always', bytes=[32, 97, 108, 119, 97, 121, 115], logprob=-4.85903e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' in', bytes=[32, 105, 110], logprob=-4.1273333e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' front', bytes=[32, 102, 114, 111, 110, 116], logprob=-2.8160932e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-2.057744e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-9.849109e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-0.04770238, top_logprobs=[]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-0.008266335, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"'t\", bytes=[39, 116], logprob=-0.12469775, top_logprobs=[]), ChatCompletionTokenLogprob(token=' be', bytes=[32, 98, 101], logprob=-1.0802739e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' seen', bytes=[32, 115, 101, 101, 110], logprob=-5.5122365e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0074691437, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content=\"The future is always in front of you but can't be seen.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323967, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=15, prompt_tokens=30, total_tokens=45, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The future is always in front of you but can't be seen.\n",
      "ChatCompletion(id='chatcmpl-B483Me1JHCCICjtI7NGLS1neLALZy', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.0074491375, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-0.00056697224, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.002154188, top_logprobs=[]), ChatCompletionTokenLogprob(token=' this', bytes=[32, 116, 104, 105, 115], logprob=-0.6470359, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-0.0178022, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-2.1769476e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-1.8193366e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.050827704, top_logprobs=[]), ChatCompletionTokenLogprob(token=' river', bytes=[32, 114, 105, 118, 101, 114], logprob=-0.07590371, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0010791336, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The answer to this riddle is a river.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323968, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=46, total_tokens=57, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to this riddle is a river.\n",
      "ChatCompletion(id='chatcmpl-B483NwTq9izlpzLuJUFVoJcfo1NPp', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.10040087, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-0.0019551564, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.10234749, top_logprobs=[]), ChatCompletionTokenLogprob(token=' this', bytes=[32, 116, 104, 105, 115], logprob=-0.5464687, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-0.0013430892, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-6.2729996e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.00023739056, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \"', bytes=[32, 34], logprob=-0.034424823, top_logprobs=[]), ChatCompletionTokenLogprob(token='foot', bytes=[102, 111, 111, 116], logprob=-0.03337352, top_logprobs=[]), ChatCompletionTokenLogprob(token='steps', bytes=[115, 116, 101, 112, 115], logprob=-0.008305102, top_logprobs=[]), ChatCompletionTokenLogprob(token='\".', bytes=[34, 46], logprob=-0.31832135, top_logprobs=[]), ChatCompletionTokenLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-0.39066848, top_logprobs=[]), ChatCompletionTokenLogprob(token=' more', bytes=[32, 109, 111, 114, 101], logprob=-5.3000836e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-2.23934, top_logprobs=[]), ChatCompletionTokenLogprob(token=' take', bytes=[32, 116, 97, 107, 101], logprob=-0.052396964, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.042964246, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.0028965247, top_logprobs=[]), ChatCompletionTokenLogprob(token=' more', bytes=[32, 109, 111, 114, 101], logprob=-3.0471343e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.040821362, top_logprobs=[]), ChatCompletionTokenLogprob(token=' leave', bytes=[32, 108, 101, 97, 118, 101], logprob=-0.0024276213, top_logprobs=[]), ChatCompletionTokenLogprob(token=' behind', bytes=[32, 98, 101, 104, 105, 110, 100], logprob=-0.00075983827, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.033184882, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The answer to this riddle is \"footsteps\". The more you take, the more you leave behind.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323969, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=23, prompt_tokens=32, total_tokens=55, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to this riddle is \"footsteps\". The more you take, the more you leave behind.\n",
      "ChatCompletion(id='chatcmpl-B483OCdwsc8PenWrrCKrktH7p2d46', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.088790044, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-0.007871952, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0011555781, top_logprobs=[]), ChatCompletionTokenLogprob(token=' this', bytes=[32, 116, 104, 105, 115], logprob=-0.8786213, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-1.247159e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-1.8908588e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-7.8033605e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.44522196, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Stap', bytes=[32, 83, 116, 97, 112], logprob=-0.95706815, top_logprobs=[]), ChatCompletionTokenLogprob(token='ler', bytes=[108, 101, 114], logprob=-1.9385403e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0018529583, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The answer to this riddle is a Stapler.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323970, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=53, total_tokens=65, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to this riddle is a Stapler.\n",
      "Testing with compute budget: 50 tokens...\n",
      "ChatCompletion(id='chatcmpl-B483SbrGFB61HMhRozuEwBbhgBtLZ', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='12', bytes=[49, 50], logprob=-0.032876477, top_logprobs=[]), ChatCompletionTokenLogprob(token=' +', bytes=[32, 43], logprob=-1.0445127e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-3.0113732e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='25', bytes=[50, 53], logprob=-9.0883464e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' equals', bytes=[32, 101, 113, 117, 97, 108, 115], logprob=-0.027154887, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.017259868, top_logprobs=[]), ChatCompletionTokenLogprob(token='37', bytes=[51, 55], logprob=-1.147242e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.003289417, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='12 + 25 equals 37.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323974, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=9, prompt_tokens=25, total_tokens=34, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "12 + 25 equals 37.\n",
      "ChatCompletion(id='chatcmpl-B483S4WomfJK5GeZEqzh2Bllavmr8', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-2.577686e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' capital', bytes=[32, 99, 97, 112, 105, 116, 97, 108], logprob=-6.704273e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-1.6240566e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' France', bytes=[32, 70, 114, 97, 110, 99, 101], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Paris', bytes=[32, 80, 97, 114, 105, 115], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0002849345, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The capital of France is Paris.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323974, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=8, prompt_tokens=24, total_tokens=32, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The capital of France is Paris.\n",
      "ChatCompletion(id='chatcmpl-B483TtFwmg32MlstsEwWhyHdgsNfq', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='To', bytes=[84, 111], logprob=-0.2600673, top_logprobs=[]), ChatCompletionTokenLogprob(token=' solve', bytes=[32, 115, 111, 108, 118, 101], logprob=-0.029622274, top_logprobs=[]), ChatCompletionTokenLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-0.12809806, top_logprobs=[]), ChatCompletionTokenLogprob(token=' x', bytes=[32, 120], logprob=-0.04878164, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.24273859, top_logprobs=[]), ChatCompletionTokenLogprob(token=' follow', bytes=[32, 102, 111, 108, 108, 111, 119], logprob=-2.8551762, top_logprobs=[]), ChatCompletionTokenLogprob(token=' these', bytes=[32, 116, 104, 101, 115, 101], logprob=-0.056227267, top_logprobs=[]), ChatCompletionTokenLogprob(token=' steps', bytes=[32, 115, 116, 101, 112, 115], logprob=-0.0015610468, top_logprobs=[]), ChatCompletionTokenLogprob(token=':\\n\\n', bytes=[58, 10, 10], logprob=-0.033155937, top_logprobs=[]), ChatCompletionTokenLogprob(token='1', bytes=[49], logprob=-0.5613628, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.07264276, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Subtract', bytes=[32, 83, 117, 98, 116, 114, 97, 99, 116], logprob=-0.06539445, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0029034202, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-5.3193703e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-0.00232546, top_logprobs=[]), ChatCompletionTokenLogprob(token=' both', bytes=[32, 98, 111, 116, 104], logprob=-0.032112557, top_logprobs=[]), ChatCompletionTokenLogprob(token=' sides', bytes=[32, 115, 105, 100, 101, 115], logprob=-0.00039194638, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.30642343, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.0038821425, top_logprobs=[]), ChatCompletionTokenLogprob(token=' equation', bytes=[32, 101, 113, 117, 97, 116, 105, 111, 110], logprob=-0.0019406538, top_logprobs=[]), ChatCompletionTokenLogprob(token=':', bytes=[58], logprob=-0.74913144, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.3496911, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-0.0050026015, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-2.1008714e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' +', bytes=[32, 43], logprob=-0.2805013, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00069825765, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-1.3856493e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' -', bytes=[32, 45], logprob=-0.00038837024, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0029534546, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-5.5122365e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.00050323125, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-6.0153056e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='9', bytes=[57], logprob=-4.246537e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' -', bytes=[32, 45], logprob=-0.00010843054, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0044650123, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-1.147242e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-1.7236222, top_logprobs=[]), ChatCompletionTokenLogprob(token=' This', bytes=[32, 84, 104, 105, 115], logprob=-0.19324984, top_logprobs=[]), ChatCompletionTokenLogprob(token=' results', bytes=[32, 114, 101, 115, 117, 108, 116, 115], logprob=-4.2614584, top_logprobs=[]), ChatCompletionTokenLogprob(token=' in', bytes=[32, 105, 110], logprob=-0.013977201, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.33462235, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-4.334534e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-9.0883464e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.0011813004, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00024620062, top_logprobs=[]), ChatCompletionTokenLogprob(token='6', bytes=[54], logprob=-5.5265704e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='.\\n', bytes=[46, 10], logprob=-0.26271418, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-0.028537542, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-8.657073e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Then', bytes=[32, 84, 104, 101, 110], logprob=-1.1688555, top_logprobs=[]), ChatCompletionTokenLogprob(token=' divide', bytes=[32, 100, 105, 118, 105, 100, 101], logprob=-0.6256623, top_logprobs=[]), ChatCompletionTokenLogprob(token=' both', bytes=[32, 98, 111, 116, 104], logprob=-0.18721654, top_logprobs=[]), ChatCompletionTokenLogprob(token=' sides', bytes=[32, 115, 105, 100, 101, 115], logprob=-0.0016639929, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.80333716, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.043119542, top_logprobs=[]), ChatCompletionTokenLogprob(token=' equation', bytes=[32, 101, 113, 117, 97, 116, 105, 111, 110], logprob=-0.027559133, top_logprobs=[]), ChatCompletionTokenLogprob(token=' by', bytes=[32, 98, 121], logprob=-0.004389171, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00022773506, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-2.1008714e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=':', bytes=[58], logprob=-0.12095589, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.30843997, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-0.0025597338, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-4.723352e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' /', bytes=[32, 47], logprob=-0.9094592, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0036339231, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-1.504853e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.00044961896, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-3.6908343e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='6', bytes=[54], logprob=-8.220573e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' /', bytes=[32, 47], logprob=-0.00024929992, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0020886387, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-1.504853e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.6617367, top_logprobs=[]), ChatCompletionTokenLogprob(token=' This', bytes=[32, 84, 104, 105, 115], logprob=-1.217786, top_logprobs=[]), ChatCompletionTokenLogprob(token=' results', bytes=[32, 114, 101, 115, 117, 108, 116, 115], logprob=-0.5704511, top_logprobs=[]), ChatCompletionTokenLogprob(token=' in', bytes=[32, 105, 110], logprob=-0.0010621059, top_logprobs=[]), ChatCompletionTokenLogprob(token=' x', bytes=[32, 120], logprob=-0.0036570802, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.0009625543, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0003122248, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-8.292095e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.35098663, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='To solve for x, follow these steps:\\n\\n1. Subtract 3 from both sides of the equation: 2x + 3 - 3 = 9 - 3. This results in 2x = 6.\\n2. Then divide both sides of the equation by 2: 2x / 2 = 6 / 2. This results in x = 3.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323975, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=82, prompt_tokens=31, total_tokens=113, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "To solve for x, follow these steps:\n",
      "\n",
      "1. Subtract 3 from both sides of the equation: 2x + 3 - 3 = 9 - 3. This results in 2x = 6.\n",
      "2. Then divide both sides of the equation by 2: 2x / 2 = 6 / 2. This results in x = 3.\n",
      "ChatCompletion(id='chatcmpl-B483WzN1YsTkYiCoK5nH2xz229ftp', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-4.3202e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' square', bytes=[32, 115, 113, 117, 97, 114, 101], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' root', bytes=[32, 114, 111, 111, 116], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-1.504853e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-2.4584822e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='144', bytes=[49, 52, 52], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-4.3202e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='12', bytes=[49, 50], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.00021462266, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The square root of 144 is 12.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323978, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=26, total_tokens=37, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The square root of 144 is 12.\n",
      "ChatCompletion(id='chatcmpl-B483W3aC79DeiXWzd2Ws1dCFDU1b6', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token=\"'\", bytes=[39], logprob=-0.021186583, top_logprobs=[]), ChatCompletionTokenLogprob(token='198', bytes=[49, 57, 56], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='4', bytes=[52], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"'\", bytes=[39], logprob=-1.2664457e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' was', bytes=[32, 119, 97, 115], logprob=-2.9352968e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' written', bytes=[32, 119, 114, 105, 116, 116, 101, 110], logprob=-2.8160932e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' by', bytes=[32, 98, 121], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' George', bytes=[32, 71, 101, 111, 114, 103, 101], logprob=-1.569009e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Orwell', bytes=[32, 79, 114, 119, 101, 108, 108], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.00015753144, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content=\"'1984' was written by George Orwell.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323978, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=23, total_tokens=34, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "'1984' was written by George Orwell.\n",
      "ChatCompletion(id='chatcmpl-B483XE7q5S8m6LRvrigSMbY1J4Yso', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-2.3392786e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' derivative', bytes=[32, 100, 101, 114, 105, 118, 97, 116, 105, 118, 101], logprob=-1.2664457e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' x', bytes=[32, 120], logprob=-7.107425e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='^', bytes=[94], logprob=-0.00240467, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-1.6240566e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.035971124, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-2.0100624e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0035969794, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The derivative of x^2 is 2x.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323979, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=26, total_tokens=38, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The derivative of x^2 is 2x.\n",
      "ChatCompletion(id='chatcmpl-B483Y9zYo1jF6GVxZw1oGYB0pkPgK', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='A', bytes=[65], logprob=-0.008446022, top_logprobs=[]), ChatCompletionTokenLogprob(token=' sponge', bytes=[32, 115, 112, 111, 110, 103, 101], logprob=-1.8624639e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.0027226103, top_logprobs=[]), ChatCompletionTokenLogprob(token=' full', bytes=[32, 102, 117, 108, 108], logprob=-2.9875326e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-3.7697225e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' holes', bytes=[32, 104, 111, 108, 101, 115], logprob=-1.2664457e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-0.024171008, top_logprobs=[]), ChatCompletionTokenLogprob(token=' still', bytes=[32, 115, 116, 105, 108, 108], logprob=-0.015395984, top_logprobs=[]), ChatCompletionTokenLogprob(token=' holds', bytes=[32, 104, 111, 108, 100, 115], logprob=-3.202099e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' water', bytes=[32, 119, 97, 116, 101, 114], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0026818444, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='A sponge is full of holes but still holds water.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323980, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=27, total_tokens=39, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "A sponge is full of holes but still holds water.\n",
      "ChatCompletion(id='chatcmpl-B483YOoR3jx6rGNDLMFzbBgR2Zhex', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='You', bytes=[89, 111, 117], logprob=-0.118925475, top_logprobs=[]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-7.147741e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' break', bytes=[32, 98, 114, 101, 97, 107], logprob=-1.9504607e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.0057269633, top_logprobs=[]), ChatCompletionTokenLogprob(token=' promise', bytes=[32, 112, 114, 111, 109, 105, 115, 101], logprob=-3.4166656e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-1.0351019, top_logprobs=[]), ChatCompletionTokenLogprob(token=' even', bytes=[32, 101, 118, 101, 110], logprob=-0.0019661048, top_logprobs=[]), ChatCompletionTokenLogprob(token=' if', bytes=[32, 105, 102], logprob=-0.002132656, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-2.4584822e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' never', bytes=[32, 110, 101, 118, 101, 114], logprob=-0.00017922651, top_logprobs=[]), ChatCompletionTokenLogprob(token=' pick', bytes=[32, 112, 105, 99, 107], logprob=-0.0013610669, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-5.6769813e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' up', bytes=[32, 117, 112], logprob=-0.00014978688, top_logprobs=[]), ChatCompletionTokenLogprob(token=' or', bytes=[32, 111, 114], logprob=-1.0445127e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' touch', bytes=[32, 116, 111, 117, 99, 104], logprob=-2.220075e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-6.1537958e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0066619655, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='You can break a promise, even if you never pick it up or touch it.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323980, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=18, prompt_tokens=33, total_tokens=51, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "You can break a promise, even if you never pick it up or touch it.\n",
      "ChatCompletion(id='chatcmpl-B483ZOotZN5amf1rOBIkAGPo0JYud', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='That', bytes=[84, 104, 97, 116], logprob=-7.2203126, top_logprobs=[]), ChatCompletionTokenLogprob(token=' would', bytes=[32, 119, 111, 117, 108, 100], logprob=-0.006559414, top_logprobs=[]), ChatCompletionTokenLogprob(token=' be', bytes=[32, 98, 101], logprob=-8.4112995e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.1814266, top_logprobs=[]), ChatCompletionTokenLogprob(token=' future', bytes=[32, 102, 117, 116, 117, 114, 101], logprob=-0.002622978, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.00636954, top_logprobs=[]), ChatCompletionTokenLogprob(token=' It', bytes=[32, 73, 116], logprob=-0.17092803, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"'s\", bytes=[39, 115], logprob=-0.13623956, top_logprobs=[]), ChatCompletionTokenLogprob(token=' always', bytes=[32, 97, 108, 119, 97, 121, 115], logprob=-0.0013270224, top_logprobs=[]), ChatCompletionTokenLogprob(token=' in', bytes=[32, 105, 110], logprob=-0.18372126, top_logprobs=[]), ChatCompletionTokenLogprob(token=' front', bytes=[32, 102, 114, 111, 110, 116], logprob=-2.8206474e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.00047273713, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.024369504, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.17406087, top_logprobs=[]), ChatCompletionTokenLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-0.00786864, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.030628473, top_logprobs=[]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-0.04140381, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"'t\", bytes=[39, 116], logprob=-0.00350385, top_logprobs=[]), ChatCompletionTokenLogprob(token=' see', bytes=[32, 115, 101, 101], logprob=-0.005589345, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.0024385513, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.16942163, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content=\"That would be the future. It's always in front of you, but you can't see it.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323981, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=22, prompt_tokens=30, total_tokens=52, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "That would be the future. It's always in front of you, but you can't see it.\n",
      "ChatCompletion(id='chatcmpl-B483bQZ9oZSrbdRsSem03lSk8PufS', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.0065861703, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-0.0007263714, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0020672334, top_logprobs=[]), ChatCompletionTokenLogprob(token=' this', bytes=[32, 116, 104, 105, 115], logprob=-0.66890883, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-0.016969008, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-1.2113979e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-1.7835755e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.050273728, top_logprobs=[]), ChatCompletionTokenLogprob(token=' river', bytes=[32, 114, 105, 118, 101, 114], logprob=-0.07834774, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0010191137, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The answer to this riddle is a river.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323983, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=46, total_tokens=57, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to this riddle is a river.\n",
      "ChatCompletion(id='chatcmpl-B483cN9mlI5GfsYeOoUVvkU9OsUJ5', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.051218748, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-0.0017413433, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.09762535, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-1.2108966, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-1.6882126e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-7.107425e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.021832138, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \"', bytes=[32, 34], logprob=-0.011638569, top_logprobs=[]), ChatCompletionTokenLogprob(token='foot', bytes=[102, 111, 111, 116], logprob=-0.1089344, top_logprobs=[]), ChatCompletionTokenLogprob(token='steps', bytes=[115, 116, 101, 112, 115], logprob=-0.010725783, top_logprobs=[]), ChatCompletionTokenLogprob(token='\".', bytes=[34, 46], logprob=-0.29294643, top_logprobs=[]), ChatCompletionTokenLogprob(token=' The', bytes=[32, 84, 104, 101], logprob=-0.23335606, top_logprobs=[]), ChatCompletionTokenLogprob(token=' more', bytes=[32, 109, 111, 114, 101], logprob=-4.310693e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' footsteps', bytes=[32, 102, 111, 111, 116, 115, 116, 101, 112, 115], logprob=-0.461134, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.0003511934, top_logprobs=[]), ChatCompletionTokenLogprob(token=' take', bytes=[32, 116, 97, 107, 101], logprob=-0.0007626919, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.0009786248, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.0011755823, top_logprobs=[]), ChatCompletionTokenLogprob(token=' more', bytes=[32, 109, 111, 114, 101], logprob=-7.9418505e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.007053626, top_logprobs=[]), ChatCompletionTokenLogprob(token=' leave', bytes=[32, 108, 101, 97, 118, 101], logprob=-0.006894274, top_logprobs=[]), ChatCompletionTokenLogprob(token=' behind', bytes=[32, 98, 101, 104, 105, 110, 100], logprob=-1.1041146e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0071573188, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The answer to the riddle is \"footsteps\". The more footsteps you take, the more you leave behind.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323984, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=24, prompt_tokens=32, total_tokens=56, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to the riddle is \"footsteps\". The more footsteps you take, the more you leave behind.\n",
      "ChatCompletion(id='chatcmpl-B483ds2D5RdWjlTLhB4NaL0LVdOtm', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.09410139, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-0.008869355, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0015512867, top_logprobs=[]), ChatCompletionTokenLogprob(token=' your', bytes=[32, 121, 111, 117, 114], logprob=-0.8494002, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-4.246537e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-1.0564331e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.00019042798, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \"', bytes=[32, 34], logprob=-0.48498002, top_logprobs=[]), ChatCompletionTokenLogprob(token='A', bytes=[65], logprob=-0.03908091, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Stap', bytes=[32, 83, 116, 97, 112], logprob=-0.005948468, top_logprobs=[]), ChatCompletionTokenLogprob(token='ler', bytes=[108, 101, 114], logprob=-1.92662e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='\".', bytes=[34, 46], logprob=-0.08480858, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The answer to your riddle is \"A Stapler\".', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323985, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=13, prompt_tokens=53, total_tokens=66, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to your riddle is \"A Stapler\".\n",
      "Testing with compute budget: 100 tokens...\n",
      "ChatCompletion(id='chatcmpl-B483e4p0GNCLQGm6Ze0baOrHIVeJB', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-3.495253, top_logprobs=[]), ChatCompletionTokenLogprob(token=' sum', bytes=[32, 115, 117, 109], logprob=-0.048612803, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-6.2729996e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-2.0935051e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='12', bytes=[49, 50], logprob=-4.3202e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.5285052, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='25', bytes=[50, 53], logprob=-7.89631e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.00021164624, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='37', bytes=[51, 55], logprob=-5.5122365e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0041382415, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The sum of 12 and 25 is 37.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323986, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=13, prompt_tokens=25, total_tokens=38, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The sum of 12 and 25 is 37.\n",
      "ChatCompletion(id='chatcmpl-B483fWZotgVCvSDQGOCe1Zf28J3xm', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-3.1737043e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' capital', bytes=[32, 99, 97, 112, 105, 116, 97, 108], logprob=-7.89631e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-2.4584822e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' France', bytes=[32, 70, 114, 97, 110, 99, 101], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Paris', bytes=[32, 80, 97, 114, 105, 115], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.00090919866, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The capital of France is Paris.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323987, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=8, prompt_tokens=24, total_tokens=32, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The capital of France is Paris.\n",
      "ChatCompletion(id='chatcmpl-B483gZj1ASgBJNqZIxJUZ4qNtK99R', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='To', bytes=[84, 111], logprob=-0.24794622, top_logprobs=[]), ChatCompletionTokenLogprob(token=' solve', bytes=[32, 115, 111, 108, 118, 101], logprob=-0.027255706, top_logprobs=[]), ChatCompletionTokenLogprob(token=' for', bytes=[32, 102, 111, 114], logprob=-0.11092846, top_logprobs=[]), ChatCompletionTokenLogprob(token=' x', bytes=[32, 120], logprob=-0.038332816, top_logprobs=[]), ChatCompletionTokenLogprob(token=' in', bytes=[32, 105, 110], logprob=-1.8443772, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.089999296, top_logprobs=[]), ChatCompletionTokenLogprob(token=' equation', bytes=[32, 101, 113, 117, 97, 116, 105, 111, 110], logprob=-0.015821546, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.05545311, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-0.00016051154, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-2.220075e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' +', bytes=[32, 43], logprob=-0.0008825228, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00038384052, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-9.0883464e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.00011462913, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.000296136, top_logprobs=[]), ChatCompletionTokenLogprob(token='9', bytes=[57], logprob=-2.6968896e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.022924678, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.220998, top_logprobs=[]), ChatCompletionTokenLogprob(token=' need', bytes=[32, 110, 101, 101, 100], logprob=-1.3857448, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0013458272, top_logprobs=[]), ChatCompletionTokenLogprob(token=' isolate', bytes=[32, 105, 115, 111, 108, 97, 116, 101], logprob=-0.5589383, top_logprobs=[]), ChatCompletionTokenLogprob(token=' x', bytes=[32, 120], logprob=-0.030103348, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.21120104, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Here', bytes=[32, 72, 101, 114, 101], logprob=-0.4539243, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"'s\", bytes=[39, 115], logprob=-0.9482918, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-1.9035621, top_logprobs=[]), ChatCompletionTokenLogprob(token=' process', bytes=[32, 112, 114, 111, 99, 101, 115, 115], logprob=-2.1488454, top_logprobs=[]), ChatCompletionTokenLogprob(token=':\\n\\n', bytes=[58, 10, 10], logprob=-0.06177988, top_logprobs=[]), ChatCompletionTokenLogprob(token='Sub', bytes=[83, 117, 98], logprob=-2.2494206, top_logprobs=[]), ChatCompletionTokenLogprob(token='tract', bytes=[116, 114, 97, 99, 116], logprob=-0.00020675888, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0027340243, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-4.8425554e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' from', bytes=[32, 102, 114, 111, 109], logprob=-0.0013261953, top_logprobs=[]), ChatCompletionTokenLogprob(token=' both', bytes=[32, 98, 111, 116, 104], logprob=-0.041091066, top_logprobs=[]), ChatCompletionTokenLogprob(token=' sides', bytes=[32, 115, 105, 100, 101, 115], logprob=-0.0005054925, top_logprobs=[]), ChatCompletionTokenLogprob(token=':', bytes=[58], logprob=-2.0714881, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \\n', bytes=[32, 10], logprob=-0.7999219, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-0.014643732, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-1.0280384e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' +', bytes=[32, 43], logprob=-0.29833528, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00073078193, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' -', bytes=[32, 45], logprob=-0.000386463, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.003284779, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-4.3202e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.0008335704, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-5.419287e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='9', bytes=[57], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' -', bytes=[32, 45], logprob=-0.00012642296, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.0028468405, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \\n', bytes=[32, 10], logprob=-1.6004994, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-1.6803608, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-1.700133e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.0015286673, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00022189408, top_logprobs=[]), ChatCompletionTokenLogprob(token='6', bytes=[54], logprob=-7.3458323e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \\n\\n', bytes=[32, 10, 10], logprob=-0.44715118, top_logprobs=[]), ChatCompletionTokenLogprob(token='Then', bytes=[84, 104, 101, 110], logprob=-0.18967377, top_logprobs=[]), ChatCompletionTokenLogprob(token=' divide', bytes=[32, 100, 105, 118, 105, 100, 101], logprob=-0.43145457, top_logprobs=[]), ChatCompletionTokenLogprob(token=' both', bytes=[32, 98, 111, 116, 104], logprob=-0.33007935, top_logprobs=[]), ChatCompletionTokenLogprob(token=' sides', bytes=[32, 115, 105, 100, 101, 115], logprob=-0.002900332, top_logprobs=[]), ChatCompletionTokenLogprob(token=' by', bytes=[32, 98, 121], logprob=-0.008430177, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00022332452, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-2.1008714e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=':', bytes=[58], logprob=-0.5727524, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \\n', bytes=[32, 10], logprob=-0.0037428334, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-0.16254725, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-1.2352386e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='/', bytes=[47], logprob=-0.92625445, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-0.00019829543, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.00070659455, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.000102708764, top_logprobs=[]), ChatCompletionTokenLogprob(token='6', bytes=[54], logprob=-1.4259645e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='/', bytes=[47], logprob=-0.0001878055, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-3.888926e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \\n', bytes=[32, 10], logprob=-0.17453595, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-0.038820058, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.00089180964, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00056876027, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-1.8193366e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \\n\\n', bytes=[32, 10, 10], logprob=-0.98403984, top_logprobs=[]), ChatCompletionTokenLogprob(token='So', bytes=[83, 111], logprob=-0.04208696, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-1.400879, top_logprobs=[]), ChatCompletionTokenLogprob(token=' solution', bytes=[32, 115, 111, 108, 117, 116, 105, 111, 110], logprob=-0.017843777, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.88039166, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.2691271, top_logprobs=[]), ChatCompletionTokenLogprob(token=' equation', bytes=[32, 101, 113, 117, 97, 116, 105, 111, 110], logprob=-0.0025490276, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-1.0987282, top_logprobs=[]), ChatCompletionTokenLogprob(token=' x', bytes=[32, 120], logprob=-0.0009991057, top_logprobs=[]), ChatCompletionTokenLogprob(token=' =', bytes=[32, 61], logprob=-0.0058996417, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-0.00017338553, top_logprobs=[]), ChatCompletionTokenLogprob(token='3', bytes=[51], logprob=-3.650519e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.012684694, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content=\"To solve for x in the equation 2x + 3 = 9, you need to isolate x. Here's the process:\\n\\nSubtract 3 from both sides: \\n2x + 3 - 3 = 9 - 3 \\n2x = 6 \\n\\nThen divide both sides by 2: \\n2x/2 = 6/2 \\nx = 3 \\n\\nSo the solution to the equation is x = 3.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323988, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=95, prompt_tokens=31, total_tokens=126, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "To solve for x in the equation 2x + 3 = 9, you need to isolate x. Here's the process:\n",
      "\n",
      "Subtract 3 from both sides: \n",
      "2x + 3 - 3 = 9 - 3 \n",
      "2x = 6 \n",
      "\n",
      "Then divide both sides by 2: \n",
      "2x/2 = 6/2 \n",
      "x = 3 \n",
      "\n",
      "So the solution to the equation is x = 3.\n",
      "ChatCompletion(id='chatcmpl-B483jMciahY4Nu6zvhI8Si7zGJ5Cf', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-5.5122365e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' square', bytes=[32, 115, 113, 117, 97, 114, 101], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' root', bytes=[32, 114, 111, 111, 116], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-2.8160932e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-3.1737043e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='144', bytes=[49, 52, 52], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-5.5122365e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='12', bytes=[49, 50], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.00016647171, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The square root of 144 is 12.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323991, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=26, total_tokens=37, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The square root of 144 is 12.\n",
      "ChatCompletion(id='chatcmpl-B483k7wyqgvTgRCvVgJunwG1BPx2V', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token=\"'\", bytes=[39], logprob=-0.04783296, top_logprobs=[]), ChatCompletionTokenLogprob(token='198', bytes=[49, 57, 56], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token='4', bytes=[52], logprob=0.0, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"'\", bytes=[39], logprob=-1.6240566e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' was', bytes=[32, 119, 97, 115], logprob=-2.6968896e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' written', bytes=[32, 119, 114, 105, 116, 116, 101, 110], logprob=-3.2929079e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' by', bytes=[32, 98, 121], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' George', bytes=[32, 71, 101, 111, 114, 103, 101], logprob=-1.3902034e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Orwell', bytes=[32, 79, 114, 119, 101, 108, 108], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.00024013224, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content=\"'1984' was written by George Orwell.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323992, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=23, total_tokens=34, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "'1984' was written by George Orwell.\n",
      "ChatCompletion(id='chatcmpl-B483lbA60pU6sVwSYZLg7LQNGOjCq', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-3.4121115e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' derivative', bytes=[32, 100, 101, 114, 105, 118, 97, 116, 105, 118, 101], logprob=-1.7432603e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-6.704273e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token=' x', bytes=[32, 120], logprob=-1.0087517e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='^', bytes=[94], logprob=-0.005509908, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-5.2001665e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.04128371, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ', bytes=[32], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='2', bytes=[50], logprob=-1.9361265e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='x', bytes=[120], logprob=-2.6060809e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.004270835, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The derivative of x^2 is 2x.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323993, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=26, total_tokens=38, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The derivative of x^2 is 2x.\n",
      "ChatCompletion(id='chatcmpl-B483mPdJhRgkUVdEkHBtT48zohHu8', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='A', bytes=[65], logprob=-0.008070161, top_logprobs=[]), ChatCompletionTokenLogprob(token=' sponge', bytes=[32, 115, 112, 111, 110, 103, 101], logprob=-1.7432603e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.0030449776, top_logprobs=[]), ChatCompletionTokenLogprob(token=' full', bytes=[32, 102, 117, 108, 108], logprob=-2.3319124e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-3.2929079e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' holes', bytes=[32, 104, 111, 108, 101, 115], logprob=-1.2664457e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-0.040028658, top_logprobs=[]), ChatCompletionTokenLogprob(token=' still', bytes=[32, 115, 116, 105, 108, 108], logprob=-0.014504876, top_logprobs=[]), ChatCompletionTokenLogprob(token=' holds', bytes=[32, 104, 111, 108, 100, 115], logprob=-3.2140193e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' water', bytes=[32, 119, 97, 116, 101, 114], logprob=-3.1281633e-07, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.0018247657, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='A sponge is full of holes but still holds water.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323994, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=27, total_tokens=39, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "A sponge is full of holes but still holds water.\n",
      "ChatCompletion(id='chatcmpl-B483muXFdk1b5lLA9WK4jdsQ6G5xf', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-2.6414962, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-0.029086078, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.057648744, top_logprobs=[]), ChatCompletionTokenLogprob(token=' this', bytes=[32, 116, 104, 105, 115], logprob=-0.3542315, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-0.003794731, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-2.2842309e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.0012561842, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \"', bytes=[32, 34], logprob=-0.4139003, top_logprobs=[]), ChatCompletionTokenLogprob(token='a', bytes=[97], logprob=-0.01120567, top_logprobs=[]), ChatCompletionTokenLogprob(token=' promise', bytes=[32, 112, 114, 111, 109, 105, 115, 101], logprob=-0.0002935135, top_logprobs=[]), ChatCompletionTokenLogprob(token='.\"', bytes=[46, 34], logprob=-1.0565917, top_logprobs=[]), ChatCompletionTokenLogprob(token=' You', bytes=[32, 89, 111, 117], logprob=-0.10827349, top_logprobs=[]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-0.043312024, top_logprobs=[]), ChatCompletionTokenLogprob(token=' break', bytes=[32, 98, 114, 101, 97, 107], logprob=-0.013903144, top_logprobs=[]), ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.010003267, top_logprobs=[]), ChatCompletionTokenLogprob(token=' promise', bytes=[32, 112, 114, 111, 109, 105, 115, 101], logprob=-1.2113979e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' without', bytes=[32, 119, 105, 116, 104, 111, 117, 116], logprob=-0.25759354, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ever', bytes=[32, 101, 118, 101, 114], logprob=-0.46694428, top_logprobs=[]), ChatCompletionTokenLogprob(token=' physically', bytes=[32, 112, 104, 121, 115, 105, 99, 97, 108, 108, 121], logprob=-0.27285624, top_logprobs=[]), ChatCompletionTokenLogprob(token=' touching', bytes=[32, 116, 111, 117, 99, 104, 105, 110, 103], logprob=-0.049326003, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.07727169, top_logprobs=[]), ChatCompletionTokenLogprob(token=' or', bytes=[32, 111, 114], logprob=-2.725398, top_logprobs=[]), ChatCompletionTokenLogprob(token=' picking', bytes=[32, 112, 105, 99, 107, 105, 110, 103], logprob=-0.0011461719, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-3.5358695e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' up', bytes=[32, 117, 112], logprob=-1.6240566e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.011971848, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The answer to this riddle is \"a promise.\" You can break a promise without ever physically touching it or picking it up.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323994, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=27, prompt_tokens=33, total_tokens=60, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to this riddle is \"a promise.\" You can break a promise without ever physically touching it or picking it up.\n",
      "ChatCompletion(id='chatcmpl-B483nqZTW3jCz7H7CRAX07LM23wcG', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.0012648788, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-1.9994148, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.00787136, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.6931295, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-3.23786e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-5.6769813e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.057080533, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \"', bytes=[32, 34], logprob=-0.0034628676, top_logprobs=[]), ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.10824342, top_logprobs=[]), ChatCompletionTokenLogprob(token=' future', bytes=[32, 102, 117, 116, 117, 114, 101], logprob=-0.15563214, top_logprobs=[]), ChatCompletionTokenLogprob(token='\".', bytes=[34, 46], logprob=-0.55259603, top_logprobs=[]), ChatCompletionTokenLogprob(token=' It', bytes=[32, 73, 116], logprob=-0.625065, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"'s\", bytes=[39, 115], logprob=-0.42366913, top_logprobs=[]), ChatCompletionTokenLogprob(token=' always', bytes=[32, 97, 108, 119, 97, 121, 115], logprob=-0.0012452321, top_logprobs=[]), ChatCompletionTokenLogprob(token=' in', bytes=[32, 105, 110], logprob=-0.051187836, top_logprobs=[]), ChatCompletionTokenLogprob(token=' front', bytes=[32, 102, 114, 111, 110, 116], logprob=-5.8484206e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' of', bytes=[32, 111, 102], logprob=-0.00053778203, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.01248505, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.3604107, top_logprobs=[]), ChatCompletionTokenLogprob(token=' but', bytes=[32, 98, 117, 116], logprob=-0.013167527, top_logprobs=[]), ChatCompletionTokenLogprob(token=' you', bytes=[32, 121, 111, 117], logprob=-0.012391441, top_logprobs=[]), ChatCompletionTokenLogprob(token=' can', bytes=[32, 99, 97, 110], logprob=-0.04480437, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"'t\", bytes=[39, 116], logprob=-0.005614239, top_logprobs=[]), ChatCompletionTokenLogprob(token=' see', bytes=[32, 115, 101, 101], logprob=-0.008438455, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.0004523606, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.029709412, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The answer to the riddle is \"The future\". It\\'s always in front of you, but you can\\'t see it.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323995, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=27, prompt_tokens=30, total_tokens=57, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to the riddle is \"The future\". It's always in front of you, but you can't see it.\n",
      "ChatCompletion(id='chatcmpl-B483pKSuWhGdapcyIYI4i5nWaznMk', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.0064624054, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-0.00049167214, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0025277452, top_logprobs=[]), ChatCompletionTokenLogprob(token=' this', bytes=[32, 116, 104, 105, 115], logprob=-0.7305734, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-0.018060386, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-6.511407e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-1.640531e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.04817723, top_logprobs=[]), ChatCompletionTokenLogprob(token=' River', bytes=[32, 82, 105, 118, 101, 114], logprob=-3.6236305, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.001257853, top_logprobs=[]), ChatCompletionTokenLogprob(token=' A', bytes=[32, 65], logprob=-1.6047239, top_logprobs=[]), ChatCompletionTokenLogprob(token=' river', bytes=[32, 114, 105, 118, 101, 114], logprob=-0.016406758, top_logprobs=[]), ChatCompletionTokenLogprob(token=' runs', bytes=[32, 114, 117, 110, 115], logprob=-0.80794, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.43835816, top_logprobs=[]), ChatCompletionTokenLogprob(token=' has', bytes=[32, 104, 97, 115], logprob=-0.13910192, top_logprobs=[]), ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.009073747, top_logprobs=[]), ChatCompletionTokenLogprob(token=' mouth', bytes=[32, 109, 111, 117, 116, 104], logprob=-0.14098214, top_logprobs=[]), ChatCompletionTokenLogprob(token=' where', bytes=[32, 119, 104, 101, 114, 101], logprob=-1.3236396, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.0037377295, top_logprobs=[]), ChatCompletionTokenLogprob(token=' meets', bytes=[32, 109, 101, 101, 116, 115], logprob=-1.425715, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-0.06726764, top_logprobs=[]), ChatCompletionTokenLogprob(token=' ocean', bytes=[32, 111, 99, 101, 97, 110], logprob=-2.407898, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.046876226, top_logprobs=[]), ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.44324046, top_logprobs=[]), ChatCompletionTokenLogprob(token=' head', bytes=[32, 104, 101, 97, 100], logprob=-0.03644354, top_logprobs=[]), ChatCompletionTokenLogprob(token=' where', bytes=[32, 119, 104, 101, 114, 101], logprob=-0.04995433, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.006901621, top_logprobs=[]), ChatCompletionTokenLogprob(token=' originates', bytes=[32, 111, 114, 105, 103, 105, 110, 97, 116, 101, 115], logprob=-1.2824419, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.1150814, top_logprobs=[]), ChatCompletionTokenLogprob(token=' and', bytes=[32, 97, 110, 100], logprob=-0.37876752, top_logprobs=[]), ChatCompletionTokenLogprob(token=' a', bytes=[32, 97], logprob=-0.0063052233, top_logprobs=[]), ChatCompletionTokenLogprob(token=' bed', bytes=[32, 98, 101, 100], logprob=-0.60110295, top_logprobs=[]), ChatCompletionTokenLogprob(token=' along', bytes=[32, 97, 108, 111, 110, 103], logprob=-1.4661084, top_logprobs=[]), ChatCompletionTokenLogprob(token=' which', bytes=[32, 119, 104, 105, 99, 104], logprob=-0.30880156, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.00076781755, top_logprobs=[]), ChatCompletionTokenLogprob(token=' flows', bytes=[32, 102, 108, 111, 119, 115], logprob=-0.025297716, top_logprobs=[]), ChatCompletionTokenLogprob(token=';', bytes=[59], logprob=-5.619409, top_logprobs=[]), ChatCompletionTokenLogprob(token=' however', bytes=[32, 104, 111, 119, 101, 118, 101, 114], logprob=-1.5741825, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.0359387, top_logprobs=[]), ChatCompletionTokenLogprob(token=' it', bytes=[32, 105, 116], logprob=-0.08756599, top_logprobs=[]), ChatCompletionTokenLogprob(token=' doesn', bytes=[32, 100, 111, 101, 115, 110], logprob=-0.96669513, top_logprobs=[]), ChatCompletionTokenLogprob(token=\"'t\", bytes=[39, 116], logprob=-0.008753193, top_logprobs=[]), ChatCompletionTokenLogprob(token=' perform', bytes=[32, 112, 101, 114, 102, 111, 114, 109], logprob=-1.1356436, top_logprobs=[]), ChatCompletionTokenLogprob(token=' any', bytes=[32, 97, 110, 121], logprob=-0.3741984, top_logprobs=[]), ChatCompletionTokenLogprob(token=' human', bytes=[32, 104, 117, 109, 97, 110], logprob=-0.9452052, top_logprobs=[]), ChatCompletionTokenLogprob(token=' actions', bytes=[32, 97, 99, 116, 105, 111, 110, 115], logprob=-0.513199, top_logprobs=[]), ChatCompletionTokenLogprob(token=' like', bytes=[32, 108, 105, 107, 101], logprob=-0.26986843, top_logprobs=[]), ChatCompletionTokenLogprob(token=' walking', bytes=[32, 119, 97, 108, 107, 105, 110, 103], logprob=-0.08386213, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-8.3278566e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' talking', bytes=[32, 116, 97, 108, 107, 105, 110, 103], logprob=-0.0024016972, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-8.44706e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' we', bytes=[32, 119, 101], logprob=-0.005861717, top_logprobs=[]), ChatCompletionTokenLogprob(token='eping', bytes=[101, 112, 105, 110, 103], logprob=-2.5703197e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=',', bytes=[44], logprob=-0.23530123, top_logprobs=[]), ChatCompletionTokenLogprob(token=' or', bytes=[32, 111, 114], logprob=-0.016773265, top_logprobs=[]), ChatCompletionTokenLogprob(token=' sleeping', bytes=[32, 115, 108, 101, 101, 112, 105, 110, 103], logprob=-0.00017112066, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.017517596, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content=\"The answer to this riddle is a River. A river runs, has a mouth where it meets the ocean, a head where it originates, and a bed along which it flows; however, it doesn't perform any human actions like walking, talking, weeping, or sleeping.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323997, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=58, prompt_tokens=46, total_tokens=104, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to this riddle is a River. A river runs, has a mouth where it meets the ocean, a head where it originates, and a bed along which it flows; however, it doesn't perform any human actions like walking, talking, weeping, or sleeping.\n",
      "ChatCompletion(id='chatcmpl-B483qneek8NzfzphW8WAtuwfKYHaK', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='They', bytes=[84, 104, 101, 121], logprob=-2.6975935, top_logprobs=[]), ChatCompletionTokenLogprob(token=' are', bytes=[32, 97, 114, 101], logprob=-3.0113732e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token=' footsteps', bytes=[32, 102, 111, 111, 116, 115, 116, 101, 112, 115], logprob=-0.007819194, top_logprobs=[]), ChatCompletionTokenLogprob(token='.', bytes=[46], logprob=-0.00080438744, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='They are footsteps.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323998, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=5, prompt_tokens=32, total_tokens=37, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "They are footsteps.\n",
      "ChatCompletion(id='chatcmpl-B483rL1YQcWprItlMXNbisbreporp', choices=[Choice(finish_reason='stop', index=0, logprobs=ChoiceLogprobs(content=[ChatCompletionTokenLogprob(token='The', bytes=[84, 104, 101], logprob=-0.124318086, top_logprobs=[]), ChatCompletionTokenLogprob(token=' answer', bytes=[32, 97, 110, 115, 119, 101, 114], logprob=-0.0098739, top_logprobs=[]), ChatCompletionTokenLogprob(token=' to', bytes=[32, 116, 111], logprob=-0.0012688051, top_logprobs=[]), ChatCompletionTokenLogprob(token=' the', bytes=[32, 116, 104, 101], logprob=-1.3942156, top_logprobs=[]), ChatCompletionTokenLogprob(token=' r', bytes=[32, 114], logprob=-1.0206721e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='iddle', bytes=[105, 100, 100, 108, 101], logprob=-8.299462e-06, top_logprobs=[]), ChatCompletionTokenLogprob(token=' is', bytes=[32, 105, 115], logprob=-0.0017317026, top_logprobs=[]), ChatCompletionTokenLogprob(token=' \"', bytes=[32, 34], logprob=-0.50898683, top_logprobs=[]), ChatCompletionTokenLogprob(token='A', bytes=[65], logprob=-0.053881414, top_logprobs=[]), ChatCompletionTokenLogprob(token=' Stap', bytes=[32, 83, 116, 97, 112], logprob=-0.013723967, top_logprobs=[]), ChatCompletionTokenLogprob(token='ler', bytes=[108, 101, 114], logprob=-2.618001e-05, top_logprobs=[]), ChatCompletionTokenLogprob(token='\".', bytes=[34, 46], logprob=-0.089547515, top_logprobs=[])], refusal=None), message=ChatCompletionMessage(content='The answer to the riddle is \"A Stapler\".', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1740323999, model='gpt-4-0613', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=13, prompt_tokens=53, total_tokens=66, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "The answer to the riddle is \"A Stapler\".\n"
     ]
    }
   ],
   "source": [
    "compute_budgets = [10, 30, 50, 100]\n",
    "responses = generate_responses(sample_dataset, compute_budgets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Responses:\n",
      "Compute Budget: 10\n",
      "Q: What is 12 + 25? | A: 37 | R: 12 + 25 equals 37.\n",
      "Compute Budget: 10\n",
      "Q: What is the capital of France? | A: Paris | R: The capital of France is Paris.\n",
      "Compute Budget: 10\n",
      "Q: Solve for x: 2x + 3 = 9 | A: x = 3 | R: To solve for x, you would first subtract 3 from both sides of the equation:\n",
      "\n",
      "2x + 3 - 3 = 9 - 3\n",
      "2x = 6\n",
      "\n",
      "Then, you divide each side by 2:\n",
      "\n",
      "2x/2 = 6/2\n",
      "x = 3\n",
      "Compute Budget: 10\n",
      "Q: What is the square root of 144? | A: 12 | R: The square root of 144 is 12.\n",
      "Compute Budget: 10\n",
      "Q: Who wrote '1984'? | A: George Orwell | R: '1984' was written by George Orwell.\n",
      "Compute Budget: 10\n",
      "Q: What is the derivative of x^2? | A: 2x | R: The derivative of x^2 is 2x.\n",
      "Compute Budget: 10\n",
      "Q: What is full of holes but still holds water? | A: sponge | R: A sponge is full of holes but still holds water.\n",
      "Compute Budget: 10\n",
      "Q: What can you break, even if you never pick it up or touch it? | A: a promise | R: You can break a promise without ever picking it up or touching it.\n",
      "Compute Budget: 10\n",
      "Q: What is always in front of you but canâ€™t be seen? | A: the future | R: The future is always in front of you but can't be seen.\n",
      "Compute Budget: 10\n",
      "Q: What can run but never walks, has a mouth but never talks, has a head but never weeps, has a bed but never sleeps? | A: river | R: The answer to this riddle is a river.\n",
      "Compute Budget: 10\n",
      "Q: The more you take, the more you leave behind. What are they? | A: footprints | R: The answer to this riddle is \"footsteps\".\n",
      "Compute Budget: 10\n",
      "Q: With pointed fangs, I sit and wait; with piercing force I crunch out fate; grabbing victims, proclaiming might; physically joining with a single bite. What am I? | A: stapler | R: The answer to your riddle is \"A Stapler\".\n",
      "Compute Budget: 30\n",
      "Q: What is 12 + 25? | A: 37 | R: 12 + 25 equals 37.\n",
      "Compute Budget: 30\n",
      "Q: What is the capital of France? | A: Paris | R: The capital of France is Paris.\n",
      "Compute Budget: 30\n",
      "Q: Solve for x: 2x + 3 = 9 | A: x = 3 | R: To solve for x, you first subtract 3 from both sides of the equation:\n",
      "\n",
      "2x + 3 - 3 = 9 - 3\n",
      "\n",
      "This simplifies to:\n",
      "\n",
      "2x = 6\n",
      "\n",
      "Then, you would divide both sides by 2:\n",
      "\n",
      "2x / 2 = 6 / 2\n",
      "\n",
      "This gives you:\n",
      "\n",
      "x = 3\n",
      "Compute Budget: 30\n",
      "Q: What is the square root of 144? | A: 12 | R: The square root of 144 is 12.\n",
      "Compute Budget: 30\n",
      "Q: Who wrote '1984'? | A: George Orwell | R: '1984' was written by George Orwell.\n",
      "Compute Budget: 30\n",
      "Q: What is the derivative of x^2? | A: 2x | R: The derivative of x^2 is 2x.\n",
      "Compute Budget: 30\n",
      "Q: What is full of holes but still holds water? | A: sponge | R: A sponge is full of holes but still holds water.\n",
      "Compute Budget: 30\n",
      "Q: What can you break, even if you never pick it up or touch it? | A: a promise | R: The answer to your riddle is \"a promise\". You can break it without ever physically touching it.\n",
      "Compute Budget: 30\n",
      "Q: What is always in front of you but canâ€™t be seen? | A: the future | R: The future is always in front of you but can't be seen.\n",
      "Compute Budget: 30\n",
      "Q: What can run but never walks, has a mouth but never talks, has a head but never weeps, has a bed but never sleeps? | A: river | R: The answer to this riddle is a river.\n",
      "Compute Budget: 30\n",
      "Q: The more you take, the more you leave behind. What are they? | A: footprints | R: The answer to this riddle is \"footsteps\". The more you take, the more you leave behind.\n",
      "Compute Budget: 30\n",
      "Q: With pointed fangs, I sit and wait; with piercing force I crunch out fate; grabbing victims, proclaiming might; physically joining with a single bite. What am I? | A: stapler | R: The answer to this riddle is a Stapler.\n",
      "Compute Budget: 50\n",
      "Q: What is 12 + 25? | A: 37 | R: 12 + 25 equals 37.\n",
      "Compute Budget: 50\n",
      "Q: What is the capital of France? | A: Paris | R: The capital of France is Paris.\n",
      "Compute Budget: 50\n",
      "Q: Solve for x: 2x + 3 = 9 | A: x = 3 | R: To solve for x, follow these steps:\n",
      "\n",
      "1. Subtract 3 from both sides of the equation: 2x + 3 - 3 = 9 - 3. This results in 2x = 6.\n",
      "2. Then divide both sides of the equation by 2: 2x / 2 = 6 / 2. This results in x = 3.\n",
      "Compute Budget: 50\n",
      "Q: What is the square root of 144? | A: 12 | R: The square root of 144 is 12.\n",
      "Compute Budget: 50\n",
      "Q: Who wrote '1984'? | A: George Orwell | R: '1984' was written by George Orwell.\n",
      "Compute Budget: 50\n",
      "Q: What is the derivative of x^2? | A: 2x | R: The derivative of x^2 is 2x.\n",
      "Compute Budget: 50\n",
      "Q: What is full of holes but still holds water? | A: sponge | R: A sponge is full of holes but still holds water.\n",
      "Compute Budget: 50\n",
      "Q: What can you break, even if you never pick it up or touch it? | A: a promise | R: You can break a promise, even if you never pick it up or touch it.\n",
      "Compute Budget: 50\n",
      "Q: What is always in front of you but canâ€™t be seen? | A: the future | R: That would be the future. It's always in front of you, but you can't see it.\n",
      "Compute Budget: 50\n",
      "Q: What can run but never walks, has a mouth but never talks, has a head but never weeps, has a bed but never sleeps? | A: river | R: The answer to this riddle is a river.\n",
      "Compute Budget: 50\n",
      "Q: The more you take, the more you leave behind. What are they? | A: footprints | R: The answer to the riddle is \"footsteps\". The more footsteps you take, the more you leave behind.\n",
      "Compute Budget: 50\n",
      "Q: With pointed fangs, I sit and wait; with piercing force I crunch out fate; grabbing victims, proclaiming might; physically joining with a single bite. What am I? | A: stapler | R: The answer to your riddle is \"A Stapler\".\n",
      "Compute Budget: 100\n",
      "Q: What is 12 + 25? | A: 37 | R: The sum of 12 and 25 is 37.\n",
      "Compute Budget: 100\n",
      "Q: What is the capital of France? | A: Paris | R: The capital of France is Paris.\n",
      "Compute Budget: 100\n",
      "Q: Solve for x: 2x + 3 = 9 | A: x = 3 | R: To solve for x in the equation 2x + 3 = 9, you need to isolate x. Here's the process:\n",
      "\n",
      "Subtract 3 from both sides: \n",
      "2x + 3 - 3 = 9 - 3 \n",
      "2x = 6 \n",
      "\n",
      "Then divide both sides by 2: \n",
      "2x/2 = 6/2 \n",
      "x = 3 \n",
      "\n",
      "So the solution to the equation is x = 3.\n",
      "Compute Budget: 100\n",
      "Q: What is the square root of 144? | A: 12 | R: The square root of 144 is 12.\n",
      "Compute Budget: 100\n",
      "Q: Who wrote '1984'? | A: George Orwell | R: '1984' was written by George Orwell.\n",
      "Compute Budget: 100\n",
      "Q: What is the derivative of x^2? | A: 2x | R: The derivative of x^2 is 2x.\n",
      "Compute Budget: 100\n",
      "Q: What is full of holes but still holds water? | A: sponge | R: A sponge is full of holes but still holds water.\n",
      "Compute Budget: 100\n",
      "Q: What can you break, even if you never pick it up or touch it? | A: a promise | R: The answer to this riddle is \"a promise.\" You can break a promise without ever physically touching it or picking it up.\n",
      "Compute Budget: 100\n",
      "Q: What is always in front of you but canâ€™t be seen? | A: the future | R: The answer to the riddle is \"The future\". It's always in front of you, but you can't see it.\n",
      "Compute Budget: 100\n",
      "Q: What can run but never walks, has a mouth but never talks, has a head but never weeps, has a bed but never sleeps? | A: river | R: The answer to this riddle is a River. A river runs, has a mouth where it meets the ocean, a head where it originates, and a bed along which it flows; however, it doesn't perform any human actions like walking, talking, weeping, or sleeping.\n",
      "Compute Budget: 100\n",
      "Q: The more you take, the more you leave behind. What are they? | A: footprints | R: They are footsteps.\n",
      "Compute Budget: 100\n",
      "Q: With pointed fangs, I sit and wait; with piercing force I crunch out fate; grabbing victims, proclaiming might; physically joining with a single bite. What am I? | A: stapler | R: The answer to the riddle is \"A Stapler\".\n"
     ]
    }
   ],
   "source": [
    "print(\"Responses:\") # Print the responses\n",
    "for item in responses:\n",
    "    print(f\"Compute Budget: {item['compute_budget']}\")\n",
    "    print(f\"Q: {item['question']} | A: {item['ground_truth']} | R: {item['response']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_utility_vs_threshold(thresholds, responses, ground_truths, risk_penalty=-1):\n",
    "    utilities = [np.mean([evaluate_utility(resp, gt, risk_penalty) for resp, gt in zip(responses, ground_truths)])\n",
    "                 for t in thresholds]\n",
    "    \n",
    "    plt.plot(thresholds, utilities, marker='o', linestyle='-')\n",
    "    plt.xlabel(\"Confidence Threshold\")\n",
    "    plt.ylabel(\"Average Utility\")\n",
    "    plt.title(\"Impact of Confidence Threshold on Utility\")\n",
    "    plt.show()\n",
    "\n",
    "plot_utility_vs_threshold([0.1, 0.3, 0.5, 0.7, 0.9], responses, sample_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
